{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zg/zvg9y3rs7j527jxfq9sc2xqc0000gn/T/ipykernel_3296/2759645877.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mnltk\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mnltk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbigrams\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgeopandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mgpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.util import bigrams\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n"
     ]
    },
    {
     "data": {
      "text/plain": "'2.5.0'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "# requires to be connected to a properly configured python environment with tensorflow etc.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "keras.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read locally\n"
     ]
    },
    {
     "data": {
      "text/plain": "         EDCS-ID                                        publication province  \\\n0  EDCS-03700724  ZPE-108-159 = Thesprotia 00001 = AE 1993, 0140...   Achaia   \n1  EDCS-03300852                                     AE 1995, 01409   Achaia   \n2  EDCS-28500283  CIL 03, 07251 = D 00214 = NDIEC-07, p 81 = AE ...   Achaia   \n3  EDCS-09400671  CIMRM-02, 02350 = IG-12, 00274 = Andros 00124 ...   Achaia   \n4  EDCS-24600769                    AE 1995, 01407 = AE 2001, 01812   Achaia   \n\n  province_list                                       place  \\\n0        Achaia                  Agios Athanasios / Photike   \n1        Achaia                                Alea / Tegea   \n2        Achaia                                Alea / Tegea   \n3        Achaia                                      Andros   \n4        Achaia  Archea Olimpia / Archaia Olympia / Olympia   \n\n                                         place_list end_yr_list  \\\n0                   ['Agios Athanasios', 'Photike']         313   \n1                                 ['Alea', 'Tegea']         276   \n2                                 ['Alea', 'Tegea']          50   \n3                                            Andros         209   \n4  ['Archea Olimpia', 'Archaia Olympia', 'Olympia']          96   \n\n                             notes_dating  \\\n0                                           \n1  to 276;   b:  276 to 282         \\n\\n    \n2                                           \n3                                           \n4                                           \n\n                                         status_list        inscr_type  ...  \\\n0  ['Augusti/Augustae', 'litterae erasae', 'ordo ...  tituli honorarii  ...   \n1           ['Augusti/Augustae', 'miliaria', 'viri']          miliaria  ...   \n2              ['Augusti/Augustae', 'leges', 'viri']             leges  ...   \n3                ['litterae erasae', 'tituli sacri']      tituli sacri  ...   \n4                                                { }               { }  ...   \n\n  within_rome nearest_city city_id_hanson city_pop_est  \\\n0       False       Dodona             31       1000.0   \n1       False        Tegea             97      46362.0   \n2       False        Tegea             97      46362.0   \n3       False       Ioulis             47       1000.0   \n4       False         Elis             35       1000.0   \n\n            city_geometry nearest_city_type nearest_city_dist  \\\n0  [20.787767, 39.546432]             minor          0.097513   \n1  [22.417226, 37.427653]               big          0.004249   \n2  [22.417226, 37.427653]               big          0.004249   \n3   [24.34625, 37.633122]             minor          0.520308   \n4  [21.435443, 37.827452]             minor          0.262624   \n\n   type_of_inscription_auto type_of_inscription_auto_prob  \\\n0     honorific inscription                           1.0   \n1         mile-/leaguestone                           1.0   \n2  public legal inscription                           1.0   \n3        votive inscription                           1.0   \n4  owner/artist inscription                           1.0   \n\n                    geometry  \n0  POINT (20.76680 39.45120)  \n1  POINT (22.41710 37.43190)  \n2  POINT (22.41710 37.43190)  \n3  POINT (24.83230 37.81880)  \n4  POINT (21.62710 37.64790)  \n\n[5 rows x 112 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EDCS-ID</th>\n      <th>publication</th>\n      <th>province</th>\n      <th>province_list</th>\n      <th>place</th>\n      <th>place_list</th>\n      <th>end_yr_list</th>\n      <th>notes_dating</th>\n      <th>status_list</th>\n      <th>inscr_type</th>\n      <th>...</th>\n      <th>within_rome</th>\n      <th>nearest_city</th>\n      <th>city_id_hanson</th>\n      <th>city_pop_est</th>\n      <th>city_geometry</th>\n      <th>nearest_city_type</th>\n      <th>nearest_city_dist</th>\n      <th>type_of_inscription_auto</th>\n      <th>type_of_inscription_auto_prob</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EDCS-03700724</td>\n      <td>ZPE-108-159 = Thesprotia 00001 = AE 1993, 0140...</td>\n      <td>Achaia</td>\n      <td>Achaia</td>\n      <td>Agios Athanasios / Photike</td>\n      <td>['Agios Athanasios', 'Photike']</td>\n      <td>313</td>\n      <td></td>\n      <td>['Augusti/Augustae', 'litterae erasae', 'ordo ...</td>\n      <td>tituli honorarii</td>\n      <td>...</td>\n      <td>False</td>\n      <td>Dodona</td>\n      <td>31</td>\n      <td>1000.0</td>\n      <td>[20.787767, 39.546432]</td>\n      <td>minor</td>\n      <td>0.097513</td>\n      <td>honorific inscription</td>\n      <td>1.0</td>\n      <td>POINT (20.76680 39.45120)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EDCS-03300852</td>\n      <td>AE 1995, 01409</td>\n      <td>Achaia</td>\n      <td>Achaia</td>\n      <td>Alea / Tegea</td>\n      <td>['Alea', 'Tegea']</td>\n      <td>276</td>\n      <td>to 276;   b:  276 to 282         \\n\\n</td>\n      <td>['Augusti/Augustae', 'miliaria', 'viri']</td>\n      <td>miliaria</td>\n      <td>...</td>\n      <td>False</td>\n      <td>Tegea</td>\n      <td>97</td>\n      <td>46362.0</td>\n      <td>[22.417226, 37.427653]</td>\n      <td>big</td>\n      <td>0.004249</td>\n      <td>mile-/leaguestone</td>\n      <td>1.0</td>\n      <td>POINT (22.41710 37.43190)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>EDCS-28500283</td>\n      <td>CIL 03, 07251 = D 00214 = NDIEC-07, p 81 = AE ...</td>\n      <td>Achaia</td>\n      <td>Achaia</td>\n      <td>Alea / Tegea</td>\n      <td>['Alea', 'Tegea']</td>\n      <td>50</td>\n      <td></td>\n      <td>['Augusti/Augustae', 'leges', 'viri']</td>\n      <td>leges</td>\n      <td>...</td>\n      <td>False</td>\n      <td>Tegea</td>\n      <td>97</td>\n      <td>46362.0</td>\n      <td>[22.417226, 37.427653]</td>\n      <td>big</td>\n      <td>0.004249</td>\n      <td>public legal inscription</td>\n      <td>1.0</td>\n      <td>POINT (22.41710 37.43190)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>EDCS-09400671</td>\n      <td>CIMRM-02, 02350 = IG-12, 00274 = Andros 00124 ...</td>\n      <td>Achaia</td>\n      <td>Achaia</td>\n      <td>Andros</td>\n      <td>Andros</td>\n      <td>209</td>\n      <td></td>\n      <td>['litterae erasae', 'tituli sacri']</td>\n      <td>tituli sacri</td>\n      <td>...</td>\n      <td>False</td>\n      <td>Ioulis</td>\n      <td>47</td>\n      <td>1000.0</td>\n      <td>[24.34625, 37.633122]</td>\n      <td>minor</td>\n      <td>0.520308</td>\n      <td>votive inscription</td>\n      <td>1.0</td>\n      <td>POINT (24.83230 37.81880)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EDCS-24600769</td>\n      <td>AE 1995, 01407 = AE 2001, 01812</td>\n      <td>Achaia</td>\n      <td>Achaia</td>\n      <td>Archea Olimpia / Archaia Olympia / Olympia</td>\n      <td>['Archea Olimpia', 'Archaia Olympia', 'Olympia']</td>\n      <td>96</td>\n      <td></td>\n      <td>{ }</td>\n      <td>{ }</td>\n      <td>...</td>\n      <td>False</td>\n      <td>Elis</td>\n      <td>35</td>\n      <td>1000.0</td>\n      <td>[21.435443, 37.827452]</td>\n      <td>minor</td>\n      <td>0.262624</td>\n      <td>owner/artist inscription</td>\n      <td>1.0</td>\n      <td>POINT (21.62710 37.64790)</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 112 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    LIREg = gpd.read_parquet(\"../data/large_data/LIREg.parquet\")\n",
    "    print(\"read locally\")\n",
    "except:\n",
    "    LIREg = gpd.read_file(\"https://zenodo.org/record/5074774/files/LIREg.geojson?download=1\", driver=\"geoJSON\")\n",
    "    LIREg.to_parquet(\"../data/large_data/LIREg.parquet\")\n",
    "    print(\"locally not available yet, need to download\")\n",
    "LIREg.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "         EDCS-ID                                        publication province  \\\n0  EDCS-03700724  ZPE-108-159 = Thesprotia 00001 = AE 1993, 0140...   Achaia   \n1  EDCS-03300852                                     AE 1995, 01409   Achaia   \n2  EDCS-28500283  CIL 03, 07251 = D 00214 = NDIEC-07, p 81 = AE ...   Achaia   \n3  EDCS-09400671  CIMRM-02, 02350 = IG-12, 00274 = Andros 00124 ...   Achaia   \n4  EDCS-24600769                    AE 1995, 01407 = AE 2001, 01812   Achaia   \n\n  province_list                                       place  \\\n0        Achaia                  Agios Athanasios / Photike   \n1        Achaia                                Alea / Tegea   \n2        Achaia                                Alea / Tegea   \n3        Achaia                                      Andros   \n4        Achaia  Archea Olimpia / Archaia Olympia / Olympia   \n\n                                         place_list end_yr_list  \\\n0                   ['Agios Athanasios', 'Photike']         313   \n1                                 ['Alea', 'Tegea']         276   \n2                                 ['Alea', 'Tegea']          50   \n3                                            Andros         209   \n4  ['Archea Olimpia', 'Archaia Olympia', 'Olympia']          96   \n\n                             notes_dating  \\\n0                                           \n1  to 276;   b:  276 to 282         \\n\\n    \n2                                           \n3                                           \n4                                           \n\n                                         status_list        inscr_type  ...  \\\n0  ['Augusti/Augustae', 'litterae erasae', 'ordo ...  tituli honorarii  ...   \n1           ['Augusti/Augustae', 'miliaria', 'viri']          miliaria  ...   \n2              ['Augusti/Augustae', 'leges', 'viri']             leges  ...   \n3                ['litterae erasae', 'tituli sacri']      tituli sacri  ...   \n4                                                { }               { }  ...   \n\n  within_rome nearest_city city_id_hanson city_pop_est  \\\n0       False       Dodona             31       1000.0   \n1       False        Tegea             97      46362.0   \n2       False        Tegea             97      46362.0   \n3       False       Ioulis             47       1000.0   \n4       False         Elis             35       1000.0   \n\n            city_geometry nearest_city_type nearest_city_dist  \\\n0  [20.787767, 39.546432]             minor          0.097513   \n1  [22.417226, 37.427653]               big          0.004249   \n2  [22.417226, 37.427653]               big          0.004249   \n3   [24.34625, 37.633122]             minor          0.520308   \n4  [21.435443, 37.827452]             minor          0.262624   \n\n   type_of_inscription_auto type_of_inscription_auto_prob  \\\n0     honorific inscription                           1.0   \n1         mile-/leaguestone                           1.0   \n2  public legal inscription                           1.0   \n3        votive inscription                           1.0   \n4  owner/artist inscription                           1.0   \n\n                    geometry  \n0  POINT (20.76680 39.45120)  \n1  POINT (22.41710 37.43190)  \n2  POINT (22.41710 37.43190)  \n3  POINT (24.83230 37.81880)  \n4  POINT (21.62710 37.64790)  \n\n[5 rows x 112 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EDCS-ID</th>\n      <th>publication</th>\n      <th>province</th>\n      <th>province_list</th>\n      <th>place</th>\n      <th>place_list</th>\n      <th>end_yr_list</th>\n      <th>notes_dating</th>\n      <th>status_list</th>\n      <th>inscr_type</th>\n      <th>...</th>\n      <th>within_rome</th>\n      <th>nearest_city</th>\n      <th>city_id_hanson</th>\n      <th>city_pop_est</th>\n      <th>city_geometry</th>\n      <th>nearest_city_type</th>\n      <th>nearest_city_dist</th>\n      <th>type_of_inscription_auto</th>\n      <th>type_of_inscription_auto_prob</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EDCS-03700724</td>\n      <td>ZPE-108-159 = Thesprotia 00001 = AE 1993, 0140...</td>\n      <td>Achaia</td>\n      <td>Achaia</td>\n      <td>Agios Athanasios / Photike</td>\n      <td>['Agios Athanasios', 'Photike']</td>\n      <td>313</td>\n      <td></td>\n      <td>['Augusti/Augustae', 'litterae erasae', 'ordo ...</td>\n      <td>tituli honorarii</td>\n      <td>...</td>\n      <td>False</td>\n      <td>Dodona</td>\n      <td>31</td>\n      <td>1000.0</td>\n      <td>[20.787767, 39.546432]</td>\n      <td>minor</td>\n      <td>0.097513</td>\n      <td>honorific inscription</td>\n      <td>1.0</td>\n      <td>POINT (20.76680 39.45120)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EDCS-03300852</td>\n      <td>AE 1995, 01409</td>\n      <td>Achaia</td>\n      <td>Achaia</td>\n      <td>Alea / Tegea</td>\n      <td>['Alea', 'Tegea']</td>\n      <td>276</td>\n      <td>to 276;   b:  276 to 282         \\n\\n</td>\n      <td>['Augusti/Augustae', 'miliaria', 'viri']</td>\n      <td>miliaria</td>\n      <td>...</td>\n      <td>False</td>\n      <td>Tegea</td>\n      <td>97</td>\n      <td>46362.0</td>\n      <td>[22.417226, 37.427653]</td>\n      <td>big</td>\n      <td>0.004249</td>\n      <td>mile-/leaguestone</td>\n      <td>1.0</td>\n      <td>POINT (22.41710 37.43190)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>EDCS-28500283</td>\n      <td>CIL 03, 07251 = D 00214 = NDIEC-07, p 81 = AE ...</td>\n      <td>Achaia</td>\n      <td>Achaia</td>\n      <td>Alea / Tegea</td>\n      <td>['Alea', 'Tegea']</td>\n      <td>50</td>\n      <td></td>\n      <td>['Augusti/Augustae', 'leges', 'viri']</td>\n      <td>leges</td>\n      <td>...</td>\n      <td>False</td>\n      <td>Tegea</td>\n      <td>97</td>\n      <td>46362.0</td>\n      <td>[22.417226, 37.427653]</td>\n      <td>big</td>\n      <td>0.004249</td>\n      <td>public legal inscription</td>\n      <td>1.0</td>\n      <td>POINT (22.41710 37.43190)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>EDCS-09400671</td>\n      <td>CIMRM-02, 02350 = IG-12, 00274 = Andros 00124 ...</td>\n      <td>Achaia</td>\n      <td>Achaia</td>\n      <td>Andros</td>\n      <td>Andros</td>\n      <td>209</td>\n      <td></td>\n      <td>['litterae erasae', 'tituli sacri']</td>\n      <td>tituli sacri</td>\n      <td>...</td>\n      <td>False</td>\n      <td>Ioulis</td>\n      <td>47</td>\n      <td>1000.0</td>\n      <td>[24.34625, 37.633122]</td>\n      <td>minor</td>\n      <td>0.520308</td>\n      <td>votive inscription</td>\n      <td>1.0</td>\n      <td>POINT (24.83230 37.81880)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EDCS-24600769</td>\n      <td>AE 1995, 01407 = AE 2001, 01812</td>\n      <td>Achaia</td>\n      <td>Achaia</td>\n      <td>Archea Olimpia / Archaia Olympia / Olympia</td>\n      <td>['Archea Olimpia', 'Archaia Olympia', 'Olympia']</td>\n      <td>96</td>\n      <td></td>\n      <td>{ }</td>\n      <td>{ }</td>\n      <td>...</td>\n      <td>False</td>\n      <td>Elis</td>\n      <td>35</td>\n      <td>1000.0</td>\n      <td>[21.435443, 37.827452]</td>\n      <td>minor</td>\n      <td>0.262624</td>\n      <td>owner/artist inscription</td>\n      <td>1.0</td>\n      <td>POINT (21.62710 37.64790)</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 112 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIREg.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "type_of_inscription_clean\nepitaph                            21520\nvotive inscription                 11728\nowner/artist inscription            3340\nhonorific inscription               3003\nbuilding/dedicatory inscription     2561\nmile-/leaguestone                   1307\nidentification inscription           850\nacclamation                          287\ndefixio                              269\nlist                                 246\nmilitary diploma                     209\nlabel                                194\nboundary inscription                 175\nelogium                              132\nletter                               119\npublic legal inscription             109\nseat inscription                      42\nprivate legal inscription             36\nprayer                                18\nassignation inscription               15\ncalendar                              10\nadnuntiatio                            1\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDH_overlap_all = LIREg[(LIREg[\"EDH-ID\"].notnull()) & (LIREg[\"EDCS-ID\"].notnull())]\n",
    "EDH_overlap = EDH_overlap_all[~EDH_overlap_all[\"type_of_inscription_clean\"].str.contains(\"NULL\")]\n",
    "EDH_overlap.groupby(\"type_of_inscription_clean\").size().sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "22"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(EDH_overlap.groupby(\"type_of_inscription_clean\").size().sort_values(ascending=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['honorific inscription',\n 'mile-/leaguestone',\n 'public legal inscription',\n 'votive inscription',\n 'owner/artist inscription',\n 'public legal inscription',\n 'honorific inscription',\n 'building/dedicatory inscription',\n 'building/dedicatory inscription',\n 'building/dedicatory inscription']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_sorted = [key for key in dict(EDH_overlap.groupby(\"type_of_inscription_clean\").size().sort_values(ascending=False))]\n",
    "# alternative, treat whole dataset as a sample\n",
    "EDH_sampled = EDH_overlap\n",
    "\n",
    "y = EDH_sampled[\"type_of_inscription_clean\"].tolist()\n",
    "y[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "{'acclamation',\n 'adnuntiatio',\n 'assignation inscription',\n 'boundary inscription',\n 'building/dedicatory inscription',\n 'calendar',\n 'defixio',\n 'elogium',\n 'epitaph',\n 'honorific inscription',\n 'identification inscription',\n 'label',\n 'letter',\n 'list',\n 'mile-/leaguestone',\n 'military diploma',\n 'owner/artist inscription',\n 'prayer',\n 'private legal inscription',\n 'public legal inscription',\n 'seat inscription',\n 'votive inscription'}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "22"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "for i, label in enumerate(list(set(y))):\n",
    "    labels_dict[label] = i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[14,\n 8,\n 17,\n 1,\n 9,\n 17,\n 14,\n 16,\n 16,\n 16,\n 12,\n 16,\n 15,\n 1,\n 15,\n 15,\n 15,\n 15,\n 15,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 12,\n 15,\n 14,\n 16,\n 14,\n 15,\n 15,\n 14,\n 15,\n 15,\n 14,\n 3,\n 14,\n 14,\n 14,\n 15,\n 15,\n 1,\n 14,\n 15,\n 15,\n 17,\n 15,\n 14,\n 14,\n 14,\n 14,\n 14,\n 15,\n 14,\n 14,\n 15,\n 14,\n 1,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 1,\n 15,\n 15,\n 14,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 14,\n 14,\n 14,\n 14,\n 14,\n 16,\n 16,\n 16,\n 14,\n 1,\n 16,\n 15,\n 17,\n 16,\n 17,\n 17,\n 14,\n 15,\n 16,\n 8,\n 15,\n 14,\n 1,\n 8,\n 1,\n 14,\n 15,\n 15,\n 15,\n 1,\n 9,\n 1,\n 1,\n 17,\n 15,\n 0,\n 15,\n 9,\n 15,\n 15,\n 15,\n 9,\n 14,\n 14,\n 14,\n 16,\n 16,\n 8,\n 1,\n 14,\n 14,\n 1,\n 1,\n 9,\n 15,\n 14,\n 15,\n 15,\n 15,\n 17,\n 15,\n 16,\n 15,\n 15,\n 16,\n 17,\n 15,\n 16,\n 15,\n 9,\n 17,\n 1,\n 16,\n 14,\n 1,\n 16,\n 14,\n 8,\n 17,\n 15,\n 1,\n 15,\n 15,\n 17,\n 7,\n 14,\n 16,\n 1,\n 1,\n 15,\n 12,\n 9,\n 9,\n 9,\n 15,\n 12,\n 1,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 16,\n 1,\n 1,\n 15,\n 15,\n 15,\n 15,\n 8,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 9,\n 12,\n 15,\n 15,\n 15,\n 1,\n 15,\n 15,\n 8,\n 15,\n 15,\n 15,\n 15,\n 15,\n 9,\n 16,\n 1,\n 16,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 9,\n 15,\n 16,\n 15,\n 1,\n 1,\n 15,\n 15,\n 1,\n 1,\n 15,\n 15,\n 15,\n 1,\n 15,\n 15,\n 15,\n 15,\n 1,\n 15,\n 15,\n 15,\n 15,\n 1,\n 15,\n 15,\n 15,\n 9,\n 1,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 14,\n 1,\n 16,\n 1,\n 15,\n 15,\n 14,\n 15,\n 14,\n 9,\n 15,\n 8,\n 15,\n 15,\n 16,\n 15,\n 15,\n 15,\n 15,\n 11,\n 15,\n 15,\n 1,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 16,\n 9,\n 15,\n 15,\n 15,\n 9,\n 9,\n 9,\n 9,\n 16,\n 16,\n 16,\n 15,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 15,\n 14,\n 15,\n 15,\n 15,\n 15,\n 15,\n 11,\n 8,\n 15,\n 15,\n 15,\n 7,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 8,\n 8,\n 8,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 15,\n 16,\n 16,\n 5,\n 1,\n 1,\n 1,\n 1,\n 1,\n 14,\n 14,\n 14,\n 14,\n 14,\n 16,\n 16,\n 15,\n 14,\n 14,\n 14,\n 14,\n 14,\n 15,\n 15,\n 15,\n 15,\n 15,\n 14,\n 15,\n 16,\n 1,\n 15,\n 16,\n 14,\n 1,\n 16,\n 1,\n 15,\n 16,\n 16,\n 16,\n 16,\n 14,\n 15,\n 1,\n 16,\n 16,\n 16,\n 14,\n 16,\n 15,\n 1,\n 1,\n 16,\n 1,\n 16,\n 16,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 16,\n 16,\n 16,\n 16,\n 1,\n 1,\n 16,\n 14,\n 16,\n 16,\n 16,\n 16,\n 14,\n 14,\n 14,\n 14,\n 14,\n 16,\n 14,\n 16,\n 14,\n 14,\n 14,\n 14,\n 14,\n 16,\n 14,\n 14,\n 16,\n 14,\n 14,\n 16,\n 16,\n 16,\n 16,\n 14,\n 16,\n 16,\n 16,\n 16,\n 16,\n 14,\n 16,\n 14,\n 14,\n 14,\n 14,\n 16,\n 16,\n 16,\n 14,\n 16,\n 16,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 16,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 16,\n 14,\n 9,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 16,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 16,\n 16,\n 16,\n 14,\n 14,\n 14,\n 14,\n 14,\n 16,\n 14,\n 14,\n 16,\n 14,\n 14,\n 14,\n 14,\n 16,\n 16,\n 14,\n 14,\n 14,\n 16,\n 14,\n 14,\n 14,\n 9,\n 9,\n 14,\n 16,\n 16,\n 1,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 16,\n 14,\n 14,\n 16,\n 16,\n 16,\n 16,\n 16,\n 14,\n 14,\n 16,\n 14,\n 14,\n 16,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 14,\n 15,\n 16,\n 16,\n 16,\n 16,\n 16,\n 9,\n 9,\n 9,\n 9,\n 16,\n 16,\n 8,\n 8,\n 8,\n 8,\n 14,\n 15,\n 14,\n 14,\n 1,\n 11,\n 11,\n 11,\n 11,\n 11,\n 11,\n 11,\n 11,\n 8,\n 1,\n 1,\n 1,\n 15,\n 1,\n 1,\n 8,\n 16,\n 14,\n 15,\n 16,\n 1,\n 16,\n 15,\n 1,\n 1,\n 14,\n 1,\n 15,\n 14,\n 1,\n 1,\n 14,\n 16,\n 14,\n 14,\n 15,\n 15,\n 15,\n 17,\n 14,\n 1,\n 14,\n 8,\n 14,\n 14,\n 16,\n 16,\n 1,\n 1,\n 15,\n 5,\n 8,\n 14,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 12,\n 12,\n 12,\n 11,\n 14,\n 1,\n 1,\n 14,\n 1,\n 15,\n 15,\n 15,\n 14,\n 15,\n 14,\n 15,\n 15,\n 1,\n 15,\n 14,\n 15,\n 15,\n 15,\n 9,\n 9,\n 1,\n 9,\n 15,\n 9,\n 16,\n 9,\n 1,\n 15,\n 9,\n 9,\n 15,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 9,\n 1,\n 15,\n 16,\n 14,\n 14,\n 16,\n 14,\n 1,\n 16,\n 16,\n 16,\n 14,\n 14,\n 16,\n 15,\n 15,\n 15,\n 15,\n 1,\n 1,\n 14,\n 14,\n 1,\n 14,\n 14,\n 14,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 14,\n 1,\n 16,\n 14,\n 1,\n 14,\n 16,\n 14,\n 15,\n 16,\n 15,\n 15,\n 15,\n 14,\n 14,\n 14,\n 15,\n 15,\n 8,\n 8,\n 8,\n 1,\n 1,\n 15,\n 8,\n 8,\n 8,\n 8,\n 8,\n 8,\n 1,\n 1,\n 15,\n 1,\n 5,\n 14,\n 15,\n 15,\n 15,\n 15,\n 15,\n 9,\n 15,\n 15,\n 15,\n 14,\n 14,\n 14,\n 14,\n 1,\n 15,\n 15,\n 1,\n 14,\n 1,\n 1,\n 14,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 1,\n 14,\n 15,\n 15,\n 16,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 16,\n 16,\n 1,\n 16,\n 16,\n 1,\n 1,\n 14,\n 14,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 1,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 20,\n 20,\n 20,\n 20,\n 20,\n 20,\n 20,\n 20,\n 20,\n 20,\n 20,\n 20,\n 20,\n 0,\n 1,\n 16,\n 16,\n 1,\n 16,\n 16,\n 14,\n 14,\n 14,\n 16,\n 1,\n 14,\n 14,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 15,\n 1,\n 8,\n 8,\n 8,\n 15,\n 5,\n 1,\n 8,\n ...]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y\n",
    "y = [labels_dict[label] for label in y]\n",
    "y# labels to integers (otherwise the code below does not work...)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[yval for yval in y if yval not in range(0,22)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def to_one_hot(y, dimension=22):\n",
    "    results = np.zeros((len(y), dimension))\n",
    "    for i, label in enumerate(y):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_labels = to_one_hot(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n        0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n        0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        1., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "inscr_texts = EDH_sampled[\"clean_text_interpretive_word\"].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def get_bigrams_underscore(inscr_text):\n",
    "    try:\n",
    "        inscr_bigrams = [\" \".join(el) for el in list(bigrams(inscr_text.split()))]\n",
    "        inscr_bigrams_ = [bigram.replace(\" \", \"_\") for bigram in inscr_bigrams]\n",
    "    except:\n",
    "        inscr_bigrams_ = []\n",
    "    return inscr_bigrams_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "[['Fortissimo_et',\n  'et_piissimo',\n  'piissimo_Caesari',\n  'Caesari_domino',\n  'domino_nostro',\n  'nostro_Galerio',\n  'Galerio_Valerio',\n  'Valerio_Maximiano',\n  'Maximiano_Pio',\n  'Pio_Felici',\n  'Felici_Invicto',\n  'Invicto_Coranius',\n  'Coranius_Titianus',\n  'Titianus_vir',\n  'vir_perfectissimus',\n  'perfectissimus_praeses',\n  'praeses_provinciae',\n  'provinciae_veteris',\n  'veteris_Epiri',\n  'Epiri_numini',\n  'numini_eorum',\n  'eorum_dicatissimus'],\n ['Imperatori_Caesari',\n  'Caesari_Marco',\n  'Marco_Annio',\n  'Annio_Floriano',\n  'Floriano_Pio',\n  'Pio_Felici',\n  'Felici_Augusto',\n  'Augusto_patri',\n  'patri_patriae',\n  'patriae_milia',\n  'milia_passuum',\n  'passuum_III',\n  'III_Imperatori',\n  'Imperatori_Caesari',\n  'Caesari_Marco',\n  'Marco_Aurelio',\n  'Aurelio_Probo',\n  'Probo_Pio',\n  'Pio_Felici',\n  'Felici_Augusto',\n  'Augusto_milia',\n  'milia_passuum',\n  'passuum_II'],\n ['Tiberius_Claudius',\n  'Claudius_Caesar',\n  'Caesar_Augustus',\n  'Augustus_Germanicus',\n  'Germanicus_pontifex',\n  'pontifex_maximus',\n  'maximus_tribunicia',\n  'tribunicia_potestate',\n  'potestate_VIIII',\n  'VIIII_imperator',\n  'imperator_XVI',\n  'XVI_pater',\n  'pater_patriae',\n  'patriae_dicit',\n  'dicit_cum',\n  'cum_et',\n  'et_colonias',\n  'colonias_et',\n  'et_municipia',\n  'municipia_non',\n  'non_solum',\n  'solum_Italiae',\n  'Italiae_verum',\n  'verum_etiam',\n  'etiam_provinciarum',\n  'provinciarum_item',\n  'item_civitatium',\n  'civitatium_cuius',\n  'cuius_que',\n  'que_provinciae',\n  'provinciae_lebare',\n  'lebare_oneribus',\n  'oneribus_vehiculorum',\n  'vehiculorum_praebendorum',\n  'praebendorum_saepe',\n  'saepe_temptavissem',\n  'temptavissem_et',\n  'et_cum',\n  'cum_satis',\n  'satis_multa',\n  'multa_remedia',\n  'remedia_invenisse',\n  'invenisse_mihi',\n  'mihi_viderer',\n  'viderer_potuit',\n  'potuit_tamen',\n  'tamen_nequitiae',\n  'nequitiae_hominum',\n  'hominum_C',\n  'C_RAS',\n  'RAS_RVM',\n  'RVM_aut',\n  'aut_falsa',\n  'falsa_nomina',\n  'nomina_ius',\n  'ius_dedit',\n  'dedit_turo',\n  'turo_ante',\n  'ante_diem'],\n ['Pro_salute',\n  'salute_Imperatorum',\n  'Imperatorum_Caesaris',\n  'Caesaris_Luci',\n  'Luci_Septimi',\n  'Septimi_Severi',\n  'Severi_et',\n  'et_Marci',\n  'Marci_Aureli',\n  'Aureli_Antonini',\n  'Antonini_Auggustorum',\n  'Auggustorum_et',\n  'et_Publi',\n  'Publi_Septimi',\n  'Septimi_Gaetae',\n  'Gaetae_Caesaris',\n  'Caesaris_Marcus',\n  'Marcus_Aurelius',\n  'Aurelius_Rufinus',\n  'Rufinus_evocatus',\n  'evocatus_Auggustorum',\n  'Auggustorum_nnostrorum',\n  'nnostrorum_Sancto',\n  'Sancto_Deo',\n  'Deo_Invicto',\n  'Invicto_speleum',\n  'speleum_constituit',\n  'constituit_cum',\n  'cum_militibus',\n  'militibus_praetorianis',\n  'praetorianis_Flavio',\n  'Flavio_Clarino',\n  'Clarino_Aelio',\n  'Aelio_Messio',\n  'Messio_Aurelio',\n  'Aurelio_Iuliano'],\n ['Octavius_Salutaris']]"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDH_bigrams_ = [get_bigrams_underscore(inscr_text) for inscr_text in inscr_texts]\n",
    "EDH_bigrams_[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "['Fortissimo_et',\n 'et_piissimo',\n 'piissimo_Caesari',\n 'Caesari_domino',\n 'domino_nostro',\n 'nostro_Galerio',\n 'Galerio_Valerio',\n 'Valerio_Maximiano',\n 'Maximiano_Pio',\n 'Pio_Felici']"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flat list of all bigrams\n",
    "bigrams_list = [el for sublist in EDH_bigrams_ for el in sublist]\n",
    "bigrams_list[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "['Dis_Manibus',\n 'vixit_annos',\n 'votum_solvit',\n 'solvit_libens',\n 'libens_merito',\n 'Iovi_Optimo',\n 'Optimo_Maximo',\n 'hic_situs',\n 'situs_est',\n 'tribunicia_potestate']"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok, let's list only N of the most common\n",
    "bigrams_mostfreq = nltk.FreqDist(bigrams_list).most_common()\n",
    "bigrams_mostfreq = [tup[0] for tup in bigrams_mostfreq]\n",
    "bigrams_mostfreq[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/geopandas/geodataframe.py:1351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Dis_Manibus': 7844,\n 'vixit_annos': 4084,\n 'votum_solvit': 3335,\n 'solvit_libens': 2982,\n 'libens_merito': 2710,\n 'Iovi_Optimo': 2413,\n 'Optimo_Maximo': 2399,\n 'hic_situs': 2338,\n 'situs_est': 2228,\n 'tribunicia_potestate': 1990,\n 'Manibus_sacrum': 1865,\n 'bene_merenti': 1585,\n 'sibi_et': 1476,\n 'Imperatori_Caesari': 1256,\n 'hic_sita': 1216,\n 'sita_est': 1155,\n 'faciendum_curavit': 1118,\n 'pro_salute': 1117,\n 'terra_levis': 1111,\n 'Imperator_Caesar': 1099,\n 'tibi_terra': 1029,\n 'sit_tibi': 999,\n 'vixit_annis': 996,\n 'pro_praetore': 932,\n 'pontifex_maximus': 837,\n 'miles_legionis': 783,\n 'pontifici_maximo': 780,\n 'est_sit': 749,\n 'maximus_tribunicia': 708,\n 'maximo_tribunicia': 706,\n 'ex_voto': 701,\n 'Pio_Felici': 698,\n 'pater_patriae': 698,\n 'patri_patriae': 687,\n 'divi_Nervae': 670,\n 'et_suis': 664,\n 'et_I': 663,\n 'Marcus_Aurelius': 656,\n 'qui_vixit': 634,\n 'piae_fidelis': 611,\n 'Caius_Iulius': 608,\n 'Marco_Aurelio': 600,\n 'libens_laetus': 588,\n 'decreto_decurionum': 585,\n 'divi_Traiani': 559,\n 'et_sibi': 558,\n 'laetus_merito': 548,\n 'legionis_II': 544,\n 'fecit_sibi': 530,\n 'vivus_fecit': 522,\n 'Augusti_pro': 521,\n 'Traiani_Parthici': 504,\n 'legionis_I': 500,\n 'quae_vixit': 462,\n 'civium_Romanorum': 459,\n 'Cai_filius': 451,\n 'Imperatoris_Caesaris': 448,\n 'beneficiarius_consularis': 445,\n 'domus_divinae': 429,\n 'pro_se': 424,\n 'milia_passuum': 420,\n 'Luci_filius': 420,\n 'Augusto_pontifici': 410,\n 'Caesari_Marco': 406,\n 'merenti_posuit': 406,\n 'annorum_XXX': 396,\n 'veteranus_legionis': 390,\n 'Antonini_Pii': 390,\n 'honorem_domus': 390,\n 'In_honorem': 387,\n 'se_et': 386,\n 'II_adiutricis': 381,\n 'Caesar_divi': 380,\n 'de_suo': 376,\n 'divi_Hadriani': 374,\n 'cohortis_I': 372,\n 'Maximo_et': 372,\n 'Marci_Aureli': 365,\n 'legato_Augusti': 355,\n 'Augustus_pontifex': 355,\n 'centurio_legionis': 354,\n 'in_suis': 345,\n 'coniugi_bene': 343,\n 'Felici_Augusto': 341,\n 'Publius_Aelius': 335,\n 'faciendum_curaverunt': 322,\n 'Caesar_Marcus': 319,\n 'Aurelio_Antonino': 315,\n 'annorum_L': 311,\n 'votum_solverunt': 305,\n 'fronte_pedes': 303,\n 'Pius_Felix': 302,\n 'in_fronte': 301,\n 'Antonino_Augusto': 300,\n 'posteris_que': 300,\n 'que_eorum': 299,\n 'Marci_filius': 297,\n 'Titus_Flavius': 296,\n 'II_vir': 296,\n 'Luci_filio': 295,\n 'ex_testamento': 293,\n 'filio_divi': 288,\n 'annorum_XX': 288,\n 'annorum_LX': 286,\n 'votum_libens': 280,\n 'suis_hic': 280,\n 'in_agro': 278,\n 'fieri_iussit': 278,\n 'annorum_XXV': 277,\n 'sua_pecunia': 276,\n 'libentes_merito': 275,\n 'Iunoni_Reginae': 274,\n 'II_viro': 269,\n 'heres_faciendum': 262,\n 'Invicto_Augusto': 261,\n 'et_II': 261,\n 'Caesari_divi': 260,\n 'solverunt_libentes': 260,\n 'Romanorum_et': 257,\n 'agro_pedes': 256,\n 'divi_Antonini': 255,\n 'viva_fecit': 255,\n 'divi_Augusti': 252,\n 'Cai_filio': 251,\n 'filio_annorum': 251,\n 'Septimi_Severi': 248,\n 'voto_posuit': 248,\n 'consul_III': 247,\n 'legionis_VII': 246,\n 'et_Genio': 245,\n 'Felici_Invicto': 244,\n 'filius_divi': 244,\n 'legionis_XIIII': 242,\n 'Pii_Felicis': 241,\n 'salute_Imperatoris': 241,\n 'Marcus_Ulpius': 239,\n 'coniugi_et': 237,\n 'testamento_fieri': 236,\n 'Tiberius_Claudius': 234,\n 'sacrum_Caius': 233,\n 'Augusti_et': 228,\n 'et_Iuliae': 228,\n 'Augusto_sacrum': 226,\n 'Luci_Septimi': 225,\n 'salute_sua': 225,\n 'legionis_XIII': 222,\n 'vivi_fecerunt': 222,\n 'XIII_geminae': 221,\n 'Invicto_Mithrae': 221,\n 'Augustus_Germanicus': 219,\n 'XIIII_geminae': 219,\n 'suis_votum': 218,\n 'Caio_Iulio': 217,\n 'Aureli_Antonini': 215,\n 'annos_LX': 214,\n 'Severi_Pii': 214,\n 'honesta_missione': 213,\n 'sacrum_Lucius': 213,\n 'consuli_II': 211,\n 'Aurelius_Antoninus': 211,\n 'consuli_III': 210,\n 'defuncto_annorum': 209,\n 'II_et': 208,\n 'iure_dicundo': 202,\n 'fecit_et': 201,\n 'annos_L': 200,\n 'miles_cohortis': 200,\n 'Silvano_Domestico': 200,\n 'maiestati_que': 199,\n 'rei_publicae': 199,\n 'Augusti_nostri': 199,\n 'filio_et': 199,\n 'numini_maiestati': 197,\n 'annos_XXX': 197,\n 'decurio_coloniae': 197,\n 'cui_praeest': 197,\n 'annorum_XXXV': 196,\n 'Caesaris_Augusti': 195,\n 'Marci_filio': 195,\n 'quorum_nomina': 194,\n 'legionis_XV': 193,\n 'Felix_Augustus': 193,\n 'I_adiutricis': 193,\n 'militavit_annos': 192,\n 'filius_annorum': 192,\n 'nobilissimo_Caesari': 191,\n 'annorum_XL': 191,\n 'Quinti_filius': 189,\n 'nepoti_divi': 189,\n 'legionis_III': 188,\n 'que_eius': 187,\n 'militum_legionis': 187,\n 'Felicis_Augusti': 187,\n 'domini_nostri': 187,\n 'Deo_Invicto': 186,\n 'defunctae_annorum': 186,\n 'legionis_X': 185,\n 'patriae_proconsuli': 185,\n 'hoc_monumentum': 185,\n 'pius_in': 185,\n 'legionis_XI': 184,\n 'merenti_fecit': 184,\n 'filio_Galeria': 184,\n 'annorum_LXX': 184,\n 'Lucius_Septimius': 183,\n 'Pro_salute': 182,\n 'Publi_filius': 182,\n 'XV_Apollinaris': 181,\n 'consul_II': 180,\n 'nomina_subscripta': 179,\n 'subscripta_sunt': 178,\n 'heredem_non': 178,\n 'non_sequetur': 178,\n 'Parthico_maximo': 177,\n 'Antoninus_Augustus': 176,\n 'filia_annorum': 176,\n 'bene_merentibus': 175,\n 'legionis_IIII': 175,\n 'sacrum_Marcus': 174,\n 'annos_XXV': 173,\n 'annos_XX': 173,\n 'Augusti_filio': 172,\n 'praetore_provinciae': 172,\n 'Lucio_Septimio': 172,\n 'pia_in': 172,\n 'legionis_XXII': 171,\n 'Genio_loci': 169,\n 'V_Macedonicae': 168,\n 'annos_XXXV': 165,\n 'locus_datus': 165,\n 'Pertinacis_Augusti': 165,\n 'tribuno_militum': 164,\n 'Caesaris_Marci': 164,\n 'Antonini_Augusti': 164,\n 'legatus_Augusti': 163,\n 'Maximo_Dolicheno': 163,\n 'veteranus_ex': 163,\n 'consularis_votum': 163,\n 'adiutricis_piae': 162,\n 'libertis_libertabus': 162,\n 'Parthici_maximi': 162,\n 'et_conubium': 162,\n 'conubium_cum': 162,\n 'Claudiae_piae': 161,\n 'Tiberio_Claudio': 161,\n 'cum_uxoribus': 161,\n 'Caius_Valerius': 161,\n 'hic_siti': 161,\n 'Augusto_et': 160,\n 'dedit_et': 160,\n 'donum_dedit': 160,\n 'libens_posuit': 160,\n 'militi_legionis': 160,\n 'et_III': 160,\n 'Antonino_Pio': 159,\n 'sua_et': 159,\n 'et_Imperator': 158,\n 'Luci_filia': 158,\n 'Pii_Pertinacis': 158,\n 'tribuniciae_potestatis': 158,\n 'Libero_Patri': 158,\n 'legionis_V': 156,\n 'XI_Claudiae': 156,\n 'filius_Quirina': 156,\n 'Flavio_Valerio': 155,\n 'VII_Claudiae': 155,\n 'Augustae_sacrum': 155,\n 'datus_decreto': 155,\n 'Maximo_Iunoni': 155,\n 'de_sua': 154,\n 'siti_sunt': 154,\n 'Augusto_Germanico': 153,\n 'quas_postea': 153,\n 'cohortis_II': 153,\n 'Septimio_Severo': 153,\n 'qui_militaverunt': 151,\n 'potestate_consuli': 151,\n 'I_Thracum': 151,\n 'uxoribus_quas': 150,\n 'sunt_in': 150,\n 'et_Marco': 149,\n 'ponendum_curavit': 149,\n 'L_hic': 149,\n 'dimissis_honesta': 148,\n 'libens_solvit': 147,\n 'monumentum_heredem': 147,\n 'potestate_II': 146,\n 'et_coniugi': 146,\n 'Antoninus_Pius': 146,\n 'III_et': 146,\n 'patris_patriae': 146,\n 'pecunia_publica': 146,\n 'Septimius_Severus': 146,\n 'Parthicus_maximus': 146,\n 'postea_duxissent': 145,\n 'I_Italicae': 145,\n 'Arabici_Adiabenici': 145,\n 'Caesar_Lucius': 145,\n 'XXII_Primigeniae': 144,\n 'quas_tunc': 144,\n 'tunc_habuissent': 144,\n 'Caesari_Lucio': 144,\n 'deabus_que': 144,\n 'Titi_filius': 143,\n 'duxissent_dumtaxat': 143,\n 'filius_et': 143,\n 'est_civitas': 143,\n 'I_Minerviae': 142,\n 'libertabus_que': 142,\n 'habuissent_cum': 142,\n 'cum_est': 142,\n 'patriae_et': 142,\n 'Augusto_Pio': 142,\n 'militaverunt_in': 142,\n 'pia_fidelis': 142,\n 'Titus_Aelius': 141,\n 'data_aut': 141,\n 'domino_nostro': 139,\n 'alae_I': 139,\n 'consularis_legionis': 139,\n 'ante_diem': 138,\n 'filius_Galeria': 138,\n 'divi_Marci': 138,\n 'plus_minus': 137,\n 'maximus_pontifex': 137,\n 'dono_dedit': 137,\n 'fecerunt_sibi': 137,\n 'III_pater': 136,\n 'si_quis': 136,\n 'X_geminae': 135,\n 'sacrum_Quintus': 135,\n 'LX_hic': 135,\n 'et_Iunoni': 135,\n 'Luci_filiae': 134,\n 'Imperatore_Caesare': 133,\n 'annorum_X': 133,\n 'emeritis_dimissis': 133,\n 'cohors_I': 133,\n 'potestate_IIII': 132,\n 'et_Caio': 132,\n 'a_solo': 132,\n 'Marci_Antonini': 132,\n 'Adiabenici_Parthici': 132,\n 'Manibus_Marcus': 131,\n 'pronepoti_divi': 131,\n 'eius_et': 131,\n 'et_Marcus': 131,\n 'XXV_hic': 131,\n 'filiae_annorum': 131,\n 'Germanicus_pontifex': 130,\n 'Marcus_Iulius': 130,\n 'Manibus_Marco': 130,\n 'Severo_Pio': 130,\n 'Tito_Aelio': 130,\n 'Soli_Invicto': 130,\n 'proconsul_et': 129,\n 'missione_quorum': 129,\n 'stipendiis_emeritis': 129,\n 'Lucius_Valerius': 128,\n 'patriae_proconsul': 128,\n 'Maximo_pro': 128,\n 'praefectus_cohortis': 127,\n 'Manibus_Lucio': 126,\n 'et_recognitum': 126,\n 'Cai_filia': 126,\n 'cum_iis': 126,\n 'IIII_Flaviae': 126,\n 'ex_imperio': 125,\n 'Severus_Pius': 125,\n 'descriptum_et': 124,\n 'Manibus_Caio': 124,\n 'Cai_Iuli': 124,\n 'recognitum_ex': 124,\n 'Augusti_Arabici': 124,\n 'Manibus_Caius': 123,\n 'ob_honorem': 123,\n 'Iuliae_Augustae': 123,\n 'Germanici_Sarmatici': 123,\n 'Pertinax_Augustus': 123,\n 'et_suorum': 123,\n 'et_sunt': 123,\n 'pecunia_sua': 122,\n 'sub_cura': 122,\n 'consul_IIII': 122,\n 'Manibus_Aurelius': 122,\n 'Caesar_Augustus': 121,\n 'res_publica': 121,\n 'annos_LXX': 121,\n 'XX_hic': 121,\n 'III_patri': 120,\n 'ex_tabula': 120,\n 'cum_suis': 120,\n 'iis_quas': 120,\n 'et_Aurelia': 120,\n 'et_peditibus': 120,\n 'iis_data': 119,\n 'Pertinaci_Augusto': 119,\n 'Auggustorum_pro': 119,\n 'Pius_Pertinax': 119,\n 'equitibus_et': 118,\n 'potestate_III': 117,\n 'Augustus_Pius': 117,\n 'nepos_divi': 117,\n 'quae_fixa': 117,\n 'fixa_est': 117,\n 'Pio_Pertinaci': 117,\n 'merenti_posuerunt': 117,\n 'peditibus_qui': 117,\n 'civitas_iis': 116,\n 'nobilissimus_Caesar': 116,\n 'Legio_XIII': 116,\n 'legato_pro': 115,\n 'Marcus_Valerius': 115,\n 'Tito_Flavio': 115,\n 'Quinti_filio': 115,\n 'est_Romae': 115,\n 'XXX_hic': 115,\n 'Luci_libertus': 114,\n 'et_heres': 114,\n 'sacrum_Iulia': 114,\n 'Titus_Aurelius': 114,\n 'Traianus_Hadrianus': 113,\n 'filio_Quirina': 112,\n 'et_Flavio': 112,\n 'liberis_posteris': 112,\n 'coniugi_pientissimae': 112,\n 'in_alis': 112,\n 'et_cohortibus': 112,\n 'Hadriano_Augusto': 111,\n 'Hadrianus_Augustus': 111,\n 'et_Publius': 111,\n 'quae_appellantur': 111,\n 'XIII_gemina': 111,\n 'annos_LXXX': 110,\n 'Manibus_et': 110,\n 'Publi_filio': 109,\n 'Nerva_Traianus': 109,\n 'sacrum_Publius': 109,\n 'Arabico_Adiabenico': 109,\n 'maximo_pontifici': 109,\n 'filio_pientissimo': 109,\n 'Caesari_Caio': 108,\n 'annos_XL': 108,\n 'Romae_in': 108,\n 'suo_posuit': 108,\n 'annorum_V': 108,\n 'III_Augustae': 107,\n 'Aelio_Hadriano': 107,\n 'Hadriano_Antonino': 107,\n 'et_Lucio': 106,\n 'Traiano_Hadriano': 106,\n 'et_Caius': 106,\n 'II_consul': 106,\n 'Augustus_Arabicus': 106,\n 'annorum_XXXX': 106,\n 'et_Marci': 105,\n 'tribunus_militum': 105,\n 'ex_decreto': 105,\n 'Arabicus_Adiabenicus': 105,\n 'Manibus_Lucius': 105,\n 'hic_sit': 105,\n 'et_Aureliae': 105,\n 'potestate_VIIII': 104,\n 'ipsis_liberis': 104,\n 'clarissimo_viro': 104,\n 'in_pace': 104,\n 'coniugi_carissimae': 104,\n 'et_filio': 104,\n 'legionis_VI': 104,\n 'patriae_consuli': 103,\n 'annos_X': 102,\n 'veterano_legionis': 102,\n 'Marci_filiae': 102,\n 'sunt_ipsis': 102,\n 'et_Imperatori': 102,\n 'Pii_Germanici': 102,\n 'Caesaris_Luci': 101,\n 'annos_LV': 101,\n 'Maximo_sacrum': 101,\n 'et_Iulia': 100,\n 'Marcus_Antonius': 100,\n 'IIIIII_vir': 100,\n 'civitatem_dedit': 100,\n 'Augusto_Arabico': 100,\n 'XXXV_hic': 100,\n 'VIII_Augustae': 100,\n 'Augustalis_coloniae': 100,\n 'quin_que': 99,\n 'Augustus_tribunicia': 99,\n 'et_Aurelius': 99,\n 'titulum_posuit': 99,\n 'Nervae_nepos': 98,\n 'nepos_Traianus': 98,\n 'eorum_civitatem': 98,\n 'sacrum_pro': 98,\n 'pontificis_maximi': 98,\n 'cohortis_III': 98,\n 'IIII_pater': 98,\n 'legionis_XXX': 98,\n 'eques_alae': 98,\n 'Valerio_Maximiano': 97,\n 'potestate_XVI': 97,\n 'Parthici_filius': 97,\n 'et_V': 97,\n 'Gaius_Iulius': 97,\n 'Cai_libertus': 96,\n 'Luci_liberta': 96,\n 'Adiabenicus_Parthicus': 96,\n 'annorum_LXXX': 96,\n 'annorum_XVIII': 96,\n 'Manibus_Aurelio': 96,\n 'Augusti_Germanici': 95,\n 'filius_Voltinia': 95,\n 'Titi_filio': 95,\n 'potestate_consul': 95,\n 'Augusti_ad': 95,\n 'II_consulibus': 95,\n 'decurionum_pecunia': 95,\n 'equo_publico': 95,\n 'Domino_nostro': 95,\n 'annos_LXV': 95,\n 'legionis_VIII': 95,\n 'dis_deabus': 95,\n 'patriae_equitibus': 95,\n 'tribuno_plebis': 94,\n 'Lucius_Iulius': 94,\n 'Pius_Augustus': 94,\n 'legato_Auggustorum': 94,\n 'consuli_proconsuli': 94,\n 'ddominorum_nnostrorum': 94,\n 'consuli_IIII': 93,\n 'decurio_municipii': 93,\n 'votum_posuit': 93,\n 'pedes_XII': 92,\n 'Cai_filiae': 92,\n 'imperio_ipsarum': 92,\n 'Adiabenico_Parthico': 92,\n 'Augusti_Pii': 92,\n 'Iulius_Verus': 92,\n 'vivus_sibi': 92,\n 'que_omnibus': 92,\n 'pro_pietate': 92,\n 'Publio_Aelio': 91,\n 'Primigeniae_piae': 91,\n 'Marco_Iulio': 91,\n 'annos_XXXX': 91,\n 'annorum_XV': 91,\n 'Maximo_Marcus': 91,\n 'I_Flavia': 91,\n 'II_patri': 90,\n 'Marci_filia': 90,\n 'sit_est': 90,\n 'annorum_LV': 90,\n 'vir_perfectissimus': 89,\n 'patriae_consul': 89,\n 'Caesari_Augusto': 89,\n 'dumtaxat_singuli': 89,\n 'posuit_et': 89,\n 'Aelius_Hadrianus': 88,\n 'Hadrianus_Antoninus': 88,\n 'IIII_viro': 88,\n 'aedili_II': 88,\n 'que_et': 88,\n 'Nervae_filius': 88,\n 'Augusti_libertus': 88,\n 'singuli_singulas': 88,\n 'vir_Augustalis': 88,\n 'II_consuli': 88,\n 'II_Augustae': 88,\n 'legati_Augusti': 88,\n 'filius_Nerva': 87,\n 'coniugi_suae': 87,\n 'Maximo_Caius': 87,\n 'legato_legionis': 86,\n 'salute_et': 86,\n 'abnepoti_divi': 86,\n 'filiae_et': 86,\n 'imperator_II': 86,\n 'coniugi_annorum': 86,\n 'obito_annorum': 86,\n 'devotus_numini': 85,\n 'et_Lucius': 85,\n 'Quintus_Iulius': 85,\n 'Valerio_Constantino': 85,\n 'legionis_XX': 85,\n 'caelibes_essent': 85,\n 'Tiberi_Caesaris': 85,\n 'LXX_hic': 85,\n 'Deo_Soli': 85,\n 'Germanici_Caesaris': 85,\n 'heres_posuit': 84,\n 'filio_dulcissimo': 84,\n 'provinciae_Africae': 83,\n 'praefecto_cohortis': 83,\n 'uxori_et': 83,\n 'Germanico_maximo': 83,\n 'essent_cum': 83,\n 'et_castrorum': 83,\n 'annos_LXXV': 83,\n 'ad_que': 82,\n 'in_muro': 82,\n 'ad_Minervam': 82,\n 'Quinti_filia': 82,\n 'militi_cohortis': 82,\n 'merenti_et': 82,\n 'II_pater': 81,\n 'Manibus_Tito': 81,\n 'mulieris_liberta': 81,\n 'que_suis': 81,\n 'Traianus_Augustus': 81,\n 'muro_post': 81,\n 'post_templum': 81,\n 'templum_divi': 81,\n 'Augusto_tribunicia': 81,\n 'LXXX_hic': 81,\n 'filiae_coniugi': 81,\n 'XXX_Ulpiae': 81,\n 'ab_Aquinco': 81,\n 'civitatem_Romanam': 80,\n 'idem_que': 80,\n 'consuli_patri': 80,\n 'et_Publio': 80,\n 'posuit_libens': 80,\n 'Marco_Antonio': 79,\n 'Deo_Mercurio': 79,\n 'heres_ex': 79,\n 'annorum_XXII': 79,\n 'Manibus_Publius': 79,\n 'Aquinco_milia': 79,\n 'II_viri': 78,\n 'Marci_libertus': 78,\n 'Aurelio_Valerio': 78,\n 'annos_V': 78,\n 'potestate_VI': 78,\n 'Nervae_adnepoti': 78,\n 'est_heres': 78,\n 'ne_que': 77,\n 'et_in': 77,\n 'Invictus_Augustus': 77,\n 'legionis_eiusdem': 77,\n 'pedes_XX': 77,\n 'qui_et': 77,\n 'patri_et': 77,\n 'filius_Claudia': 77,\n 'suorum_que': 77,\n 'Tiberi_Claudi': 76,\n 'Manibus_Iuliae': 76,\n 'sibi_viva': 76,\n 'pater_et': 76,\n 'XX_Valeriae': 76,\n 'LV_hic': 76,\n 'XXX_stipendiorum': 76,\n 'filius_vivus': 75,\n 'vir_iure': 75,\n 'et_divi': 75,\n 'potestate_patri': 75,\n 'viro_iure': 75,\n 'I_Hispanorum': 75,\n 'supra_scriptae': 75,\n 'LX_et': 75,\n 'stlitibus_iudicandis': 74,\n 'Germanicus_maximus': 74,\n 'potestate_V': 74,\n 'Manibus_Publio': 74,\n 'maximi_tribunicia': 74,\n 'dedit_dedicavit': 74,\n 'Augustae_matri': 74,\n 'L_et': 74,\n 'ex_beneficiario': 74,\n 'Deo_Marti': 74,\n 'testamento_faciendum': 74,\n 'et_Aurelio': 74,\n 'I_I': 74,\n 'et_Hygiae': 74,\n 'divi_Vespasiani': 73,\n 'Manibus_Titus': 73,\n 'Felix_Invictus': 73,\n 'suo_fecit': 73,\n 'et_libertis': 73,\n 'coniugi_karissimae': 73,\n 'filiae_uxori': 73,\n 'decurioni_coloniae': 73,\n 'proconsuli_et': 73,\n 'hic_est': 73,\n 'Augusti_filius': 73,\n 'et_Flavia': 73,\n 'Domestico_sacrum': 73,\n 'que_posteris': 73,\n 'Severi_et': 72,\n 'menses_V': 72,\n 'patri_bene': 72,\n 'pontifice_maximo': 72,\n 'filio_piissimo': 72,\n 'annorum_XVI': 72,\n 'sibi_fecit': 72,\n 'annorum_III': 72,\n 'II_Italicae': 72,\n 'Parthici_filio': 71,\n 'ob_merita': 71,\n 'tabula_aenea': 71,\n 'Septimius_Geta': 71,\n 'annos_LXXXV': 71,\n 'LXXV_hic': 71,\n 'annorum_LXV': 71,\n 'Iulio_Philippo': 71,\n 'Hadriani_filius': 71,\n 'Galerio_Valerio': 70,\n 'Iulius_Cai': 70,\n 'aut_si': 70,\n 'Iulio_Vero': 70,\n 'Augusto_Parthico': 70,\n 'mater_filio': 70,\n 'Caesar_Caius': 70,\n 'patri_pientissimo': 70,\n 'annorum_XLV': 70,\n 'annorum_XII': 70,\n 'appellantur_I': 70,\n 'annos_XXXXV': 70,\n 'fidelis_et': 70,\n 'curam_agente': 69,\n 'matri_et': 69,\n 'Nervae_pronepos': 69,\n 'centurioni_legionis': 69,\n 'annorum_et': 69,\n 'Apollinaris_annorum': 69,\n 'sibi_vivus': 68,\n 'III_consuli': 68,\n 'Parthici_et': 68,\n 'Severi_Alexandri': 68,\n 'coniugi_incomparabili': 68,\n 'filius_Sergia': 68,\n 'Pius_pontifex': 68,\n 'et_vicenis': 68,\n 'et_Aelia': 68,\n 'pluribusve_stipendiis': 68,\n 'sacris_faciundis': 67,\n 'praefecto_fabrum': 67,\n 'aenea_quae': 67,\n 'suo_et': 67,\n 'filius_Augustus': 67,\n 'filius_Papiria': 67,\n 'menses_VI': 67,\n 'III_consul': 67,\n 'libentes_laeti': 67,\n 'Lucius_Cornelius': 67,\n 'Gallorum_et': 67,\n 'si_qui': 66,\n 'patre_patriae': 66,\n 'coniugi_eius': 66,\n 'LXV_hic': 66,\n 'matri_pientissimae': 66,\n 'qui_eorum': 66,\n 'Valeriae_victricis': 66,\n 'salute_domini': 66,\n 'sunt_civitatem': 66,\n 'Auggustorum_et': 65,\n 'quo_que': 65,\n 'Hadriani_Augusti': 65,\n 'filio_suo': 65,\n 'XXX_et': 65,\n 'consul_pater': 65,\n 'Publi_libertus': 65,\n 'in_honorem': 65,\n 'X_hic': 65,\n 'Ulpiae_victricis': 65,\n 'et_et': 65,\n 'consularis_pro': 65,\n 'et_Aeliae': 65,\n 'Caio_Valerio': 64,\n 'vir_clarissimus': 64,\n 'Germanicus_Dacicus': 64,\n 'annos_XV': 64,\n 'V_et': 64,\n 'est_Caius': 64,\n 'annos_III': 64,\n 'solvit_merito': 64,\n 'VI_victricis': 64,\n 'annorum_II': 64,\n 'annorum_XXVI': 64,\n 'obitae_annorum': 64,\n 'filius_Pollia': 63,\n 'IIIIII_viro': 63,\n 'ex_HS': 63,\n 'pedes_X': 63,\n 'libens_animo': 63,\n 'consul_proconsul': 63,\n 'centurio_cohortis': 63,\n 'Publio_Licinio': 63,\n 'filia_vixit': 63,\n 'beneficiario_consularis': 63,\n 'pientissimo_et': 63,\n 'viva_sibi': 63,\n 'et_pontes': 63,\n 'et_filiae': 63,\n 'pronepos_Titus': 63,\n 'consulibus_cohortis': 63,\n 'Herculi_Augusto': 63,\n 'Parthici_nepos': 63,\n 'praeses_provinciae': 62,\n 'Publius_Septimius': 62,\n 'I_et': 62,\n 'Tiberius_Iulius': 62,\n 'Silvano_sacrum': 62,\n 'et_filiis': 62,\n 'divinae_Iovi': 62,\n 'stipendiorum_X': 62,\n 'Romanam_qui': 62,\n 'eorum_non': 62,\n 'non_haberent': 62,\n 'sua_suorum': 62,\n 'Marco_Ulpio': 61,\n 'qui_caelibes': 61,\n 'VI_vir': 61,\n 'est_testamento': 61,\n 'filiae_dulcissimae': 61,\n 'filiae_pientissimae': 61,\n 'Titi_Aeli': 61,\n 'semper_Augusto': 61,\n 'Severo_Alexandro': 61,\n 'Silvano_Augusto': 61,\n 'voto_suscepto': 61,\n 'at_que': 61,\n 'Lucius_Aemilius': 61,\n 'geminae_votum': 61,\n 'XXXX_hic': 61,\n 'vias_et': 61,\n 'dumtaxat_singulis': 61,\n 'quinis_et': 61,\n 'VIIII_imperator': 60,\n 'poni_iussit': 60,\n 'XII_in': 60,\n 'IIII_vir': 60,\n 'coniux_et': 60,\n 'Constantio_et': 60,\n 'et_Valeria': 60,\n 'Augustae_matris': 60,\n 'LXXXV_hic': 60,\n 'se_vivo': 60,\n 'laeti_merito': 60,\n 'geminae_Martiae': 60,\n 'primus_pilus': 60,\n 'III_Thracum': 60,\n 'maximus_tribuniciae': 59,\n 'annos_XLV': 59,\n 'filio_Papiria': 59,\n 'Maximo_Lucius': 59,\n 'voto_libens': 59,\n 'nostro_Flavio': 58,\n 'proconsuli_provinciae': 58,\n 'procuratoris_Augusti': 58,\n 'Lucio_Aurelio': 58,\n 'pronepos_divi': 58,\n 'Septimio_Getae': 58,\n 'divi_Severi': 58,\n 'Sexti_filius': 58,\n 'potestate_XV': 58,\n 'IIII_patri': 58,\n 'Britannico_maximo': 58,\n 'et_heredes': 58,\n 'Lucius_Aurelius': 58,\n 'annorum_LXXV': 58,\n 'aut_cum': 58,\n 'vicenis_pluribusve': 58,\n 'coloniae_Sarmizegetusae': 58,\n 'Nervae_nepoti': 57,\n 'nepoti_Traiano': 57,\n 'annos_XVIII': 57,\n 'annos_XXVI': 57,\n 'cohortis_IIII': 57,\n 'marito_bene': 57,\n 'principi_iuventutis': 57,\n 'Valerio_Constantio': 57,\n 'IIII_et': 57,\n 'Caesari_Flavio': 57,\n 'Martiae_victricis': 57,\n 'coniugi_pientissimo': 57,\n 'suorum_votum': 57,\n 'annorum_XXIII': 57,\n 'filio_eius': 57,\n 'perpetuae_securitati': 57,\n 'I_Aelia': 57,\n 'et_IIII': 57,\n 'veterano_ex': 57,\n 'II_Flavia': 57,\n 'militavit_annis': 56,\n 'imperatori_II': 56,\n 'viro_Augustali': 56,\n 'annos_XVI': 56,\n 'in_suo': 56,\n 'voto_posuerunt': 56,\n 'maximo_Britannico': 56,\n 'Augusti_legionis': 56,\n 'annos_VII': 56,\n 'vir_egregius': 56,\n 'II_Augusta': 56,\n 'annorum_hic': 56,\n 'Publi_filia': 56,\n 'annorum_IIII': 56,\n 'XL_stipendiorum': 56,\n 'Luci_Pulli': 56,\n 'collegii_fabrum': 56,\n 'Lusitanorum_et': 56,\n 'Aesculapio_et': 55,\n 'nostri_Imperatoris': 55,\n 'quicum_que': 55,\n 'potestate_VIII': 55,\n 'et_Iulius': 55,\n 'Hadriani_filio': 55,\n 'Antonio_Gordiano': 55,\n 'pondo_libras': 55,\n 'merentibus_posuit': 55,\n 'procurator_Augusti': 55,\n 'annos_II': 55,\n 'III_Italicae': 55,\n 'vivi_sibi': 55,\n 'Matronis_Vacallinehis': 55,\n 'consul_V': 54,\n 'viro_perfectissimo': 54,\n 'numini_eius': 54,\n 'in_foro': 54,\n 'devota_numini': 54,\n 'Augustus_et': 54,\n 'laetus_libens': 54,\n 'annorum_VII': 54,\n 'filius_votum': 54,\n 'Imperatore_Antonino': 54,\n 'singulas_ante': 54,\n 'perfectissimus_praeses': 53,\n 'annis_XXX': 53,\n 'X_viro': 53,\n 'est_in': 53,\n 'et_memoriae': 53,\n 'procuratori_Augusti': 53,\n 'annos_XII': 53,\n 'faciundum_curavit': 53,\n 'consul_designatus': 53,\n 'maximo_Germanico': 53,\n 'equiti_Romano': 53,\n 'ceteris_que': 53,\n 'Imperatore_domino': 53,\n 'heredes_faciendum': 53,\n 'Silvano_Silvestri': 53,\n 'I_Alpinorum': 53,\n 'equitum_Romanorum': 52,\n 'viro_stlitibus': 52,\n 'Divi_Iuli': 52,\n 'Publio_Septimio': 52,\n 'XXXXV_hic': 52,\n 'Constantino_Pio': 52,\n 'libertus_et': 52,\n 'marito_optimo': 52,\n 'Messio_Quinto': 52,\n 'Raetorum_et': 52,\n 'Auggustorum_nnostrorum': 51,\n 'et_Flavius': 51,\n 'Publi_filiae': 51,\n 'V_dies': 51,\n 'pedes_XV': 51,\n 'mulieris_libertus': 51,\n 'filii_et': 51,\n 'divi_Commodi': 51,\n 'Verus_Maximinus': 51,\n 'Maximinus_Pius': 51,\n 'est_Titus': 51,\n 'fecerunt_et': 51,\n 'II_proconsul': 51,\n 'imperator_XII': 51,\n 'Titus_Iulius': 51,\n 'suo_faciendum': 51,\n 'Lucio_Licinio': 51,\n 'Manibus_Iulia': 51,\n 'XXXV_stipendiorum': 51,\n 'Maximo_cohors': 51,\n 'Manibus_Aurelia': 51,\n 'legati_legionis': 51,\n 'ex_decurione': 51,\n 'fidelis_votum': 51,\n 'veterana_et': 51,\n 'adiutricis_votum': 51,\n 'coloniae_Aquincensium': 51,\n 'Minerviae_piae': 50,\n 'Iulio_Cai': 50,\n 'Quinti_filiae': 50,\n 'II_proconsuli': 50,\n 'est_et': 50,\n 'Lucio_Valerio': 50,\n 'IIII_consul': 50,\n 'Augustis_sacrum': 50,\n 'aram_posuit': 50,\n 'Aureli_Severi': 50,\n 'XL_hic': 50,\n 'salute_ddominorum': 50,\n 'sacrum_Titus': 50,\n 'Maximo_Titus': 50,\n 'mater_et': 50,\n 'VIII_Kalendas': 50,\n 'divinae_deo': 50,\n 'et_perpetuae': 50,\n 'stipendiorum_XX': 50,\n 'merito_posuit': 50,\n ...}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bigrams_freq_dict = dict(nltk.FreqDist(bigrams_list).most_common())\n",
    "EDH_sampled[\"bigrams\"] = EDH_bigrams_\n",
    "all_bigrams_freq_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "N = 10\n",
    "weighted_bigrams_all = []\n",
    "for cat in EDH_sampled[\"type_of_inscription_clean\"].unique():\n",
    "    EDH_cat = EDH_sampled[EDH_sampled[\"type_of_inscription_clean\"]==cat]\n",
    "    bigrams_list = [el for sublist in EDH_cat[\"bigrams\"].tolist() for el in sublist]\n",
    "    cat_bigrams_freq_dict = dict(nltk.FreqDist(bigrams_list).most_common())\n",
    "    weighted_bigrams = []\n",
    "    for word in cat_bigrams_freq_dict.keys():\n",
    "        if cat_bigrams_freq_dict[word] >= 5: # it it appears at least twice\n",
    "            weighted_bigrams.append((word, cat_bigrams_freq_dict[word] / all_bigrams_freq_dict[word]))\n",
    "    # choose only N of the most characteristic bigrams for given category\n",
    "    weighted_bigrams = sorted(weighted_bigrams, key=lambda tup: tup[1], reverse=True)[:N]\n",
    "    weighted_bigrams = [tup[0] for tup in weighted_bigrams]\n",
    "    weighted_bigrams_all.extend(weighted_bigrams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def combine_status_list_and_bigrams(el_status, el_bigrams, el_material):\n",
    "    # preprocess status:\n",
    "    try: el_status = eval(el_status)\n",
    "    except: pass\n",
    "    if isinstance(el_status, list):\n",
    "        new_el_status = el_status\n",
    "    elif isinstance(el_status, str):\n",
    "        new_el_status = [el_status]\n",
    "    else:\n",
    "        new_el_status = []\n",
    "    new_el_status = [el.replace(\" \", \"_\") for el in new_el_status]\n",
    "    # preprocess material:\n",
    "    if el_material is None:\n",
    "        el_material = []\n",
    "    else:\n",
    "        el_material = el_material.partition(\": \")[0] #\n",
    "        el_material = el_material.split(\", \")\n",
    "        el_material = [el.replace(\" \", \"_\").replace(\"?\", \"\") for el in el_material]\n",
    "    # combine status, bigrams and material\n",
    "    new_el = new_el_status + el_bigrams + el_material\n",
    "    new_el = \" \".join(new_el)\n",
    "    return new_el, new_el_status, el_material"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "status_bigrams_list = []\n",
    "status_list = []\n",
    "material_list = []\n",
    "for el_status, el_bigrams, el_material in zip(EDH_sampled[\"status_list\"].tolist(), EDH_sampled[\"bigrams\"].tolist(), EDH_sampled[\"Material\"].tolist()):\n",
    "    new_el, new_status, el_material = combine_status_list_and_bigrams(el_status, el_bigrams, el_material)\n",
    "    status_bigrams_list.append(new_el)\n",
    "    status_list.append(new_status)\n",
    "    material_list.extend(el_material)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "18"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "materials_freqdist = nltk.FreqDist(material_list).most_common()\n",
    "len(materials_freqdist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "[('lapis', 22042),\n ('opus_figlinae', 2247),\n ('aes', 796),\n ('plumbum', 528),\n ('lignum', 289),\n ('argentum', 289),\n ('aurum', 82),\n ('vitrum', 63),\n ('ferrum', 60),\n ('tectorium', 58),\n ('musivum', 27),\n ('steatitis', 11),\n ('os', 10),\n ('cyprum', 6),\n ('gemma', 4),\n ('rupes', 4),\n ('corium', 1),\n ('sucineus', 1)]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "materials_freqdist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "18"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 20\n",
    "materials_N = [tup[0] for tup in materials_freqdist[:N]]\n",
    "len(materials_N)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "['viri',\n 'tituli_sepulcrales',\n 'tria_nomina',\n 'tituli_sacri',\n 'mulieres',\n 'milites',\n 'nomen_singulare',\n 'Augusti/Augustae',\n 'tituli_operum',\n 'tituli_fabricationis']"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_list_flat = [el for sublist in status_list for el in sublist]\n",
    "status_N = [tup[0] for tup in nltk.FreqDist(status_list_flat).most_common(100)] ### we had 228 in total\n",
    "status_N[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "['viri',\n 'tituli_sepulcrales',\n 'tria_nomina',\n 'tituli_sacri',\n 'mulieres',\n 'milites',\n 'nomen_singulare',\n 'Augusti/Augustae',\n 'tituli_operum',\n 'tituli_fabricationis']"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_status = EDH_sampled[\"status_list\"].tolist()[0]\n",
    "status_list_flat = [el for sublist in status_list for el in sublist]\n",
    "status_N = [tup[0] for tup in nltk.FreqDist(status_list_flat).most_common(100)] ### we had 228 in total\n",
    "status_N[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "37"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(status_N)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "vocab = status_N + bigrams_mostfreq[:10000] + materials_N\n",
    "vocab = list(set(vocab))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "subset_size = 5000\n",
    "vectorizer = TfidfVectorizer(token_pattern=r\"\\w+\\/?|\\_\\w+\", vocabulary=vocab, lowercase=False)\n",
    "X = vectorizer.fit_transform(status_bigrams_list[:subset_size])\n",
    "X = X.A"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "x_train, x_test, one_hot_train_labels, one_hot_test_labels = train_test_split(X[:subset_size], one_hot_labels[:subset_size], test_size=0.2, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., ..., 0., 0., 0.])"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4000"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1000"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n       0., 0., 0., 0., 0.])"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our network\n",
    "\n",
    "\n",
    "This topic classification problem looks very similar to our previous movie review classification problem: in both cases, we are trying to \n",
    "classify short snippets of text. There is however a new constraint here: the number of output classes has gone from 2 to 46, i.e. the \n",
    "dimensionality of the output space is much larger. \n",
    "\n",
    "In a stack of `Dense` layers like what we were using, each layer can only access information present in the output of the previous layer. \n",
    "If one layer drops some information relevant to the classification problem, this information can never be recovered by later layers: each \n",
    "layer can potentially become an \"information bottleneck\". In our previous example, we were using 16-dimensional intermediate layers, but a \n",
    "16-dimensional space may be too limited to learn to separate 46 different classes: such small layers may act as information bottlenecks, \n",
    "permanently dropping relevant information.\n",
    "\n",
    "For this reason we will use larger layers. Let's go with 64 units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "10053"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(len(x_train[0]),)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(22, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are two other things you should note about this architecture:\n",
    "\n",
    "* We are ending the network with a `Dense` layer of size 22. This means that for each input sample, our network will output a 22-dimensional vector. Each entry in this vector (each dimension) will encode a different output class.\n",
    "* The last layer uses a `softmax` activation. You have already seen this pattern in the MNIST example. It means that the network will output a _probability distribution_ over the 22 different output classes, i.e. for every input sample, the network will produce a 22-dimensional output vector where `output[i]` is the probability that the sample belongs to class `i`. The 22 scores will sum to 1.\n",
    "\n",
    "The best loss function to use in this case is `categorical_crossentropy`. It measures the distance between two probability distributions: \n",
    "in our case, between the probability distribution output by our network, and the true distribution of the labels. By minimizing the \n",
    "distance between these two distributions, we train our network to output something as close as possible to the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "def f1_weighted(y_true, y_pred):\n",
    "    y_true = np.ndarray.argmax(y_true.numpy(), axis=1)\n",
    "    y_pred = np.ndarray.argmax(y_pred.numpy(), axis=1)\n",
    "    return f1_score(y_true, y_pred, average=\"weighted\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1_weighted]) #'accuracy']) #, f1_weighted])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating our approach\n",
    "\n",
    "Let's set apart 1,000 samples in our training data to use as a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "array([15, 16,  1,  9, 14, 15,  1, 15,  1, 14, 15,  1, 15, 14,  1, 15, 15,\n       12, 15,  8,  1,  1,  9, 15, 15, 14, 15,  1,  8, 15, 15, 17, 15, 14,\n       15, 15, 15, 15, 15, 14,  1,  1,  1, 15, 14, 15, 15, 16, 14, 14,  8,\n       15, 15,  1, 15,  1, 14, 16, 15, 15,  1, 17, 15,  9, 15, 15, 15, 15,\n       15,  1, 15,  1, 15, 15, 14, 14, 20, 15, 15, 15, 15, 15, 14, 14, 15,\n       15, 15, 14, 14, 15, 15, 15,  1, 15,  1, 15,  1, 15,  8, 15, 15,  1,\n        1, 15, 15,  8, 15, 15,  1,  1,  1, 15, 15,  1, 15, 15,  1, 15,  1,\n       15, 15,  8, 15, 14,  9, 15, 15, 15, 16, 15, 15, 15,  1,  1, 15,  8,\n       14, 15, 15, 14, 15, 14,  1, 15, 16,  9,  1, 15, 14,  9, 15, 15, 15,\n       15, 14, 15, 15, 12, 15, 15,  9, 15,  1, 15,  1, 15, 15, 15, 15, 15,\n       15, 14, 15, 15,  1, 15,  8, 15, 21, 15, 11, 15, 15, 16, 15,  1,  1,\n        1, 15, 15,  1, 15, 15, 15, 15, 14, 17, 15,  1, 15, 15,  1, 15, 20,\n        9,  9, 15,  1, 15, 15, 15,  1, 15, 15,  9,  0, 15, 15, 16,  1,  9,\n       15,  9, 15,  1, 15, 14, 15,  1, 15,  1, 15, 14, 14, 16, 15,  8,  1,\n        1, 14,  1, 12,  9, 14,  9, 15, 15, 15, 14, 15, 15, 14, 14,  9, 11,\n       15, 15, 15, 15, 15, 15, 15, 15,  9, 15, 14, 14, 15,  1, 15, 16, 11,\n       15, 15, 14, 15, 15, 14, 15, 16, 15, 15, 14, 14, 15,  1, 14, 15, 14,\n        9,  1, 14,  1, 14,  9, 14, 15, 15, 15,  9, 16, 15, 15, 14, 15, 15,\n       15, 14, 14, 16, 14,  8, 12, 20, 15, 15, 15, 15, 14, 12, 15, 15, 15,\n       15,  8, 14, 12, 15, 15,  1,  1, 14, 16, 15, 14,  1,  1, 14, 15, 15,\n        8, 14,  9,  1, 15,  1,  1, 15, 15, 15,  8, 15, 15,  1, 16, 15,  9,\n       14, 15,  1,  1, 15, 15, 14, 14, 14, 16, 12, 15, 14, 15, 15, 14,  1,\n       14, 15, 15, 15,  1,  9, 15, 15, 15, 15, 16,  1, 14, 11, 15, 14, 15,\n       15, 15, 15, 16, 14, 14,  1, 15, 15, 15,  1, 15,  9, 15, 15,  1, 11,\n        9, 15,  1, 15, 20,  1, 14,  1,  1, 14,  1,  1,  1, 15, 14, 15, 15,\n       15, 17,  9, 15, 15,  1, 14,  1,  1, 15, 15, 15,  1,  9, 14, 14, 15,\n       15,  9, 15,  1, 15, 12,  8, 15,  9,  1, 15, 15, 14,  1,  1, 15, 20,\n       15, 15, 15, 15, 15, 16,  1,  1, 15,  1, 15, 15, 14, 15, 14, 15, 15,\n        1, 15, 16, 15,  1, 15,  1,  5, 15,  1, 15,  1,  9,  1,  1, 15, 15,\n       15, 15, 15, 14,  9,  1,  1,  1, 12, 15, 17, 15, 15, 14,  9, 14, 16,\n       15,  1, 15, 15, 15,  1, 15, 14,  8, 15,  8, 15,  1, 15, 14, 15, 14,\n       14, 14, 15,  9,  8,  1, 15, 15,  1, 15,  1, 16, 16, 14, 14, 15, 14,\n       16, 15, 14,  1,  9, 15, 15,  1, 15,  1, 14, 15, 15,  9, 15, 15, 15,\n        1, 15, 14, 14, 15, 15, 15, 15, 15, 14,  1, 15, 14, 15, 14,  7,  8,\n       15, 15,  9, 15, 15,  1,  1, 15,  1, 14, 14, 15, 15, 15, 15, 15, 15,\n        1, 16, 15,  1, 15,  1, 15,  1,  1, 17, 14, 15, 14,  1, 14, 15, 15,\n       15,  8,  1, 15, 15, 15, 16, 15,  9, 15, 15,  1, 15, 15, 15, 15, 15,\n       15,  9, 15, 15, 15, 14, 15, 15,  1, 15, 15, 16,  8, 15,  1,  9,  1,\n       15, 15, 15, 15, 16,  1, 15,  8, 15, 15, 15, 14, 15,  9, 15, 15, 15,\n       11,  1, 16,  1, 15, 15, 15, 11, 15, 14,  1, 15,  1, 15, 14, 14,  1,\n        1,  1, 16,  1, 15, 15, 14, 15, 14,  8, 14, 15, 15, 15, 15, 14,  9,\n       15, 16, 14,  9, 15, 15, 15, 15, 15, 15,  1,  1, 15, 15, 15,  8, 14,\n        1, 15, 15, 15, 16, 15, 15, 15,  1, 15, 14,  1, 15,  1, 21, 14,  1,\n       15, 15, 16, 15, 16, 15, 14, 15,  1, 15, 15, 15, 14, 15,  1, 15, 14,\n       14, 15, 14, 15,  1, 12, 15, 14, 15, 12,  1, 15, 15, 15, 15, 14, 15,\n       15, 15,  9, 15, 15, 16, 14,  1,  1, 15, 15, 14, 15, 15, 15, 15, 14,\n       15, 14, 15, 15,  1, 15, 15, 15, 15, 15,  1, 15, 15,  1,  1, 14, 14,\n       15, 14, 14,  1, 15, 15,  9,  9,  8, 12, 15,  1,  8, 15,  1,  1,  8,\n       14, 15, 15,  1, 15, 14, 15,  1,  1, 15, 15, 15, 16, 15,  1, 14, 15,\n       16, 15,  1, 14,  1, 15, 12, 15,  1, 15, 14,  1, 15,  1,  1, 15, 15,\n       15, 15,  1,  9,  1, 15,  1, 15, 15, 15,  9, 15, 16, 15,  1, 15, 15,\n       15, 15, 15, 15,  1, 20,  9, 14, 15,  1, 15, 16,  9,  9, 15,  1, 15,\n        1, 15,  1,  1, 16, 15, 15, 15,  1, 15, 15,  1, 15, 14, 15, 14,  9,\n       15, 15,  1, 14, 14, 14, 15, 15,  1, 15, 14, 15, 15, 15, 15, 14, 15,\n       15,  9, 15, 15, 15, 15,  8, 15,  1, 14, 14, 16,  9, 15,  1, 12,  1,\n       15, 15,  1, 17, 14, 14, 14, 14,  7,  8,  1, 15, 14, 15, 15,  1,  9,\n        9,  1,  8, 16, 15, 15, 15, 15, 14,  9, 14,  1, 15, 15,  1, 17, 15,\n        8, 14, 15,  1, 15, 15, 15, 16,  1, 15, 15, 15, 15, 15,  1, 15, 15,\n        1, 14, 15,  1, 15, 15, 15, 15, 15,  1, 15, 15, 14,  1])"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndarray.argmax(y_val, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our network for 30 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 3.0909 - f1_weighted: 0.0982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 122ms/step - loss: 3.0483 - f1_weighted: 0.2529 - val_loss: 2.8839 - val_f1_weighted: 0.4043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 2.8207 - f1_weighted: 0.4077 - val_loss: 2.6030 - val_f1_weighted: 0.4456\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 2.5218 - f1_weighted: 0.4507 - val_loss: 2.2663 - val_f1_weighted: 0.4484\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 85ms/step - loss: 2.1820 - f1_weighted: 0.4592 - val_loss: 1.9183 - val_f1_weighted: 0.4548\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 86ms/step - loss: 1.8370 - f1_weighted: 0.4674 - val_loss: 1.6247 - val_f1_weighted: 0.5429\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 85ms/step - loss: 1.5475 - f1_weighted: 0.5706 - val_loss: 1.4063 - val_f1_weighted: 0.5786\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 1.3549 - f1_weighted: 0.5948 - val_loss: 1.2402 - val_f1_weighted: 0.6101\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 85ms/step - loss: 1.1574 - f1_weighted: 0.6467 - val_loss: 1.1114 - val_f1_weighted: 0.6328\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 1.0193 - f1_weighted: 0.6744 - val_loss: 1.0055 - val_f1_weighted: 0.6669\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 0.9081 - f1_weighted: 0.7145 - val_loss: 0.9193 - val_f1_weighted: 0.6934\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.8147 - f1_weighted: 0.7351 - val_loss: 0.8491 - val_f1_weighted: 0.7065\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.7231 - f1_weighted: 0.7631 - val_loss: 0.7922 - val_f1_weighted: 0.7137\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 0.6854 - f1_weighted: 0.7669 - val_loss: 0.7450 - val_f1_weighted: 0.7603\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 0.5936 - f1_weighted: 0.7975 - val_loss: 0.7044 - val_f1_weighted: 0.7854\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.5600 - f1_weighted: 0.8208 - val_loss: 0.6709 - val_f1_weighted: 0.7922\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 87ms/step - loss: 0.5018 - f1_weighted: 0.8485 - val_loss: 0.6435 - val_f1_weighted: 0.8010\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 86ms/step - loss: 0.4739 - f1_weighted: 0.8567 - val_loss: 0.6192 - val_f1_weighted: 0.7998\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.4388 - f1_weighted: 0.8606 - val_loss: 0.5999 - val_f1_weighted: 0.7956\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 85ms/step - loss: 0.4284 - f1_weighted: 0.8636 - val_loss: 0.5811 - val_f1_weighted: 0.8082\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 0.4020 - f1_weighted: 0.8736 - val_loss: 0.5689 - val_f1_weighted: 0.8161\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display its loss and accuracy curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['loss', 'f1_weighted', 'val_loss', 'val_f1_weighted'])"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "f1 = history.history['f1_weighted']\n",
    "val_f1 = history.history['val_f1_weighted']\n",
    "\n",
    "plt.plot(epochs, f1, 'bo', label='Training f1')\n",
    "plt.plot(epochs, val_f1, 'b', label='Validation f1')\n",
    "plt.title('Training and validation f1 (weighted)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "subset_size = len(status_bigrams_list)\n",
    "vectorizer = TfidfVectorizer(token_pattern=r\"\\w+\\/?|\\_\\w+\", vocabulary=vocab, lowercase=False)\n",
    "X = vectorizer.fit_transform(status_bigrams_list[:subset_size])\n",
    "X = X.A\n",
    "\n",
    "# TRAIN vs TEST\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(X, one_hot_labels[:subset_size], test_size=0.1, random_state=1)\n",
    "\n",
    "# actual TRAIN vs. internal VALIDATION data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.1, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37397, 10053) (37397, 22) (4156, 10053) (4156, 22) (4618, 10053) (4618, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    x_train.shape,\n",
    "    y_train.shape,\n",
    "    x_val.shape,\n",
    "    y_val.shape,\n",
    "    x_test.shape,\n",
    "    y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.9588 - f1_weighted: 0.3204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 3s 153ms/step - loss: 1.9289 - f1_weighted: 0.3292 - val_loss: 0.6395 - val_f1_weighted: 0.8207\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 2s 128ms/step - loss: 0.5761 - f1_weighted: 0.8088 - val_loss: 0.4763 - val_f1_weighted: 0.8533\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 2s 123ms/step - loss: 0.4300 - f1_weighted: 0.8544 - val_loss: 0.4692 - val_f1_weighted: 0.8572\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 2s 119ms/step - loss: 0.3704 - f1_weighted: 0.8703 - val_loss: 0.4975 - val_f1_weighted: 0.8300\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 2s 126ms/step - loss: 0.3247 - f1_weighted: 0.8847 - val_loss: 0.4528 - val_f1_weighted: 0.8764\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 2s 118ms/step - loss: 0.2824 - f1_weighted: 0.9040 - val_loss: 0.4574 - val_f1_weighted: 0.8888\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 2s 126ms/step - loss: 0.2520 - f1_weighted: 0.9155 - val_loss: 0.4821 - val_f1_weighted: 0.8808\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 2s 121ms/step - loss: 0.2427 - f1_weighted: 0.9206 - val_loss: 0.4938 - val_f1_weighted: 0.8648\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 2s 126ms/step - loss: 0.2257 - f1_weighted: 0.9226 - val_loss: 0.4958 - val_f1_weighted: 0.8853\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 2s 121ms/step - loss: 0.2165 - f1_weighted: 0.9254 - val_loss: 0.5361 - val_f1_weighted: 0.8875\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 2s 116ms/step - loss: 0.2113 - f1_weighted: 0.9259 - val_loss: 0.5589 - val_f1_weighted: 0.8755\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 2s 117ms/step - loss: 0.1994 - f1_weighted: 0.9307 - val_loss: 0.6223 - val_f1_weighted: 0.8729\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 2s 115ms/step - loss: 0.2004 - f1_weighted: 0.9324 - val_loss: 0.6614 - val_f1_weighted: 0.8522\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 2s 116ms/step - loss: 0.1992 - f1_weighted: 0.9311 - val_loss: 0.6156 - val_f1_weighted: 0.8715\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 2s 116ms/step - loss: 0.1976 - f1_weighted: 0.9345 - val_loss: 0.6433 - val_f1_weighted: 0.8779\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 2s 115ms/step - loss: 0.1947 - f1_weighted: 0.9333 - val_loss: 0.6820 - val_f1_weighted: 0.8788\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 2s 115ms/step - loss: 0.1851 - f1_weighted: 0.9367 - val_loss: 0.6799 - val_f1_weighted: 0.8717\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 2s 113ms/step - loss: 0.1883 - f1_weighted: 0.9361 - val_loss: 0.6778 - val_f1_weighted: 0.8816\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 2s 115ms/step - loss: 0.1815 - f1_weighted: 0.9395 - val_loss: 0.7138 - val_f1_weighted: 0.8539\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 2s 113ms/step - loss: 0.1792 - f1_weighted: 0.9366 - val_loss: 0.6677 - val_f1_weighted: 0.8812\n",
      "  3/145 [..............................] - ETA: 6s - loss: 0.6796 - f1_weighted: 0.8977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 7s 49ms/step - loss: 0.6753 - f1_weighted: 0.8587\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(len(x_train[0]),)))\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(len(x_train[0]),)))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(22, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1_weighted])\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=20,\n",
    "          batch_size=2048,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0.6753405928611755, 0.858659029006958]"
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f1_weighted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our approach reaches an accuracy of ~78%. With a balanced binary classification problem, the accuracy reached by a purely random classifier \n",
    "would be 50%, but in our case it is closer to 19%, so our results seem pretty good, at least when compared to a random baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating predictions on new data\n",
    "\n",
    "We can verify that the `predict` method of our model instance returns a probability distribution over all 46 topics. Let's generate topic \n",
    "predictions for all of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in `predictions` is a vector of length 46:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients in this vector sum to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zg/zvg9y3rs7j527jxfq9sc2xqc0000gn/T/ipykernel_40805/398723103.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest entry is the predicted class, i.e. the class with the highest probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A different way to handle the labels and the loss\n",
    "\n",
    "We mentioned earlier that another way to encode the labels would be to cast them as an integer tensor, like such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The only thing it would change is the choice of the loss function. Our previous loss, `categorical_crossentropy`, expects the labels to \n",
    "follow a categorical encoding. With integer labels, we should use `sparse_categorical_crossentropy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new loss function is still mathematically the same as `categorical_crossentropy`; it just has a different interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the importance of having sufficiently large intermediate layers\n",
    "\n",
    "\n",
    "We mentioned earlier that since our final outputs were 46-dimensional, we should avoid intermediate layers with much less than 46 hidden \n",
    "units. Now let's try to see what happens when we introduce an information bottleneck by having intermediate layers significantly less than \n",
    "46-dimensional, e.g. 4-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our network now seems to peak at ~71% test accuracy, a 8% absolute drop. This drop is mostly due to the fact that we are now trying to \n",
    "compress a lot of information (enough information to recover the separation hyperplanes of 46 classes) into an intermediate space that is \n",
    "too low-dimensional. The network is able to cram _most_ of the necessary information into these 8-dimensional representations, but not all \n",
    "of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further experiments\n",
    "\n",
    "* Try using larger or smaller layers: 32 units, 128 units...\n",
    "* We were using two hidden layers. Now try to use a single hidden layer, or three hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "\n",
    "Here's what you should take away from this example:\n",
    "\n",
    "* If you are trying to classify data points between N classes, your network should end with a `Dense` layer of size N.\n",
    "* In a single-label, multi-class classification problem, your network should end with a `softmax` activation, so that it will output a \n",
    "probability distribution over the N output classes.\n",
    "* _Categorical crossentropy_ is almost always the loss function you should use for such problems. It minimizes the distance between the \n",
    "probability distributions output by the network, and the true distribution of the targets.\n",
    "* There are two ways to handle labels in multi-class classification:\n",
    "    ** Encoding the labels via \"categorical encoding\" (also known as \"one-hot encoding\") and using `categorical_crossentropy` as your loss \n",
    "function.\n",
    "    ** Encoding the labels as integers and using the `sparse_categorical_crossentropy` loss function.\n",
    "* If you need to classify data into a large number of categories, then you should avoid creating information bottlenecks in your network by having \n",
    "intermediate layers that are too small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "socdiv_venv",
   "language": "python",
   "display_name": "socdiv_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}