{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sddk\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 1000 # to see all columns\n",
    "import json\n",
    "import re\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from functools import partial\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.util import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file located in a public folder\n"
     ]
    }
   ],
   "source": [
    "EDHCSg = sddk.read_file(\"EDHCSg.geojson\", \"gdf\", \"a9237c5ea642d4714bcdefb03f70a1f4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to train the model, we will work with a subset of the for which we have both the EDH and EDCS attributes\n",
    "# we will call it EDHg\n",
    "EDHg = EDHCSg[(EDHCSg[\"EDH-ID\"].notnull()) & (EDHCSg[\"EDCS-ID\"].notnull())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type_of_inscription_clean\n",
       "epitaph                            21520\n",
       "votive inscription                 11728\n",
       "NULL                                3745\n",
       "owner/artist inscription            3340\n",
       "honorific inscription               3003\n",
       "building/dedicatory inscription     2561\n",
       "mile-/leaguestone                   1307\n",
       "identification inscription           850\n",
       "acclamation                          287\n",
       "defixio                              269\n",
       "list                                 246\n",
       "military diploma                     209\n",
       "label                                194\n",
       "boundary inscription                 175\n",
       "elogium                              132\n",
       "letter                               119\n",
       "public legal inscription             109\n",
       "seat inscription                      42\n",
       "private legal inscription             36\n",
       "prayer                                18\n",
       "assignation inscription               15\n",
       "calendar                              10\n",
       "adnuntiatio                            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the most common types of inscriptions\n",
    "EDHg.groupby(\"type_of_inscription_clean\").size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can focus on some EDCS attributes (i.e. firt 28 columns) which might be good predictors of `type_of_inscription_clean` in EDH. First, look at `status_list`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on `status_list`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['Augusti/Augustae', 'litterae erasae', 'ordo equester', 'tituli honorarii', 'tria nomina']\",\n",
       " \"['Augusti/Augustae', 'miliaria', 'viri']\",\n",
       " \"['Augusti/Augustae', 'leges', 'viri']\",\n",
       " \"['litterae erasae', 'tituli sacri']\",\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " \"['Augusti/Augustae', 'tituli fabricationis', 'viri']\",\n",
       " {}]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDHg[\"status_list\"].tolist()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tituli honorarii',\n",
       " 'miliaria',\n",
       " 'leges',\n",
       " 'tituli sacri',\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " 'tituli fabricationis',\n",
       " {}]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# among other information, status list also contains an information about inscription type:\n",
    "EDHg[\"inscr_type\"].tolist()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some applications, it will be useful to transform it into string, with all two-word phrases treated as one word \n",
    "# (therefore underscore)\n",
    "status_lists = []\n",
    "for el in EDHg[\"status_list\"].tolist():\n",
    "    try: el = eval(el)\n",
    "    except: pass\n",
    "    if isinstance(el, list):\n",
    "        new_el = el\n",
    "    elif isinstance(el, str):\n",
    "        new_el = [el]\n",
    "    else: \n",
    "        new_el = []\n",
    "    new_el = \" \".join([el.replace(\" \", \"_\") for el in new_el])\n",
    "    status_lists.append(new_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Augusti/Augustae litterae_erasae ordo_equester tituli_honorarii tria_nomina',\n",
       " 'Augusti/Augustae miliaria viri',\n",
       " 'Augusti/Augustae leges viri',\n",
       " 'litterae_erasae tituli_sacri',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Augusti/Augustae tituli_fabricationis viri',\n",
       " '']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_lists[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['honorific inscription',\n",
       " 'mile-/leaguestone',\n",
       " 'public legal inscription',\n",
       " 'votive inscription',\n",
       " 'owner/artist inscription',\n",
       " 'public legal inscription',\n",
       " 'honorific inscription',\n",
       " 'building/dedicatory inscription',\n",
       " 'building/dedicatory inscription',\n",
       " 'NULL']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = EDHg[\"type_of_inscription_clean\"].tolist()\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 16), match='Augusti_Augustae'>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(\"\\w+\\/?|\\_\\w+\", \"Augusti_Augustae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the vector model\n",
    "# sklearn does not like some special characters, therefore it is important to defined what is accepted as a token_pattern\n",
    "vectorizer = CountVectorizer(token_pattern=r\"\\w+\\/?|\\_\\w+\")\n",
    "X = vectorizer.fit_transform(status_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X, y):\n",
    "    \"\"\"\n",
    "    Create and train the Support Vector Machine.\n",
    "    \"\"\"\n",
    "    svm = SVC(C=1000000.0, gamma='auto', kernel='rbf')\n",
    "    svm.fit(X, y)\n",
    "    return svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm = train_svm(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svm.predict(X_test)\n",
    "print(svm.score(X_test, y_test))\n",
    "print(confusion_matrix(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4992"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4992"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, False, True, True, True, True, True]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only where the predictor is present\n",
    "predictors_present = [np.any(el) for el in X_test.todense()]\n",
    "predictors_present[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4135"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter for the ones with predictors\n",
    "len(np.array(y_test)[predictors_present])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8773881499395405"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the performance on datapoints for which we have something in the \"status_list\"\n",
    "svm.score(X_test.todense()[predictors_present], np.array(y_test)[predictors_present])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine `status_list` & `clean_text_interpretive_word`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next step would be to build a model combining the information from the `status_list` with an informatation from the text of the inscription (i.e. `clean_text_interpretive_word`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "inscr_texts = EDHg[\"clean_text_interpretive_word\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The language of inscriptions is characterized by a number of standardized phrases, which often determine the type of insription. Treated separately, \"Dis\" and \"Manibus\" might be confusing, but treated as a bigram, they bear a crucial information about the type of inscription.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams_underscore(inscr_text):\n",
    "    try:\n",
    "        inscr_bigrams = [\" \".join(el) for el in list(bigrams(inscr_text.split()))]\n",
    "        inscr_bigrams_ = [bigram.replace(\" \", \"_\") for bigram in inscr_bigrams]\n",
    "    except:\n",
    "        inscr_bigrams_ = []\n",
    "    return inscr_bigrams_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Fortissimo_et',\n",
       "  'et_piissimo',\n",
       "  'piissimo_Caesari',\n",
       "  'Caesari_domino',\n",
       "  'domino_nostro',\n",
       "  'nostro_Galerio',\n",
       "  'Galerio_Valerio',\n",
       "  'Valerio_Maximiano',\n",
       "  'Maximiano_Pio',\n",
       "  'Pio_Felici',\n",
       "  'Felici_Invicto',\n",
       "  'Invicto_Coranius',\n",
       "  'Coranius_Titianus',\n",
       "  'Titianus_vir',\n",
       "  'vir_perfectissimus',\n",
       "  'perfectissimus_praeses',\n",
       "  'praeses_provinciae',\n",
       "  'provinciae_veteris',\n",
       "  'veteris_Epiri',\n",
       "  'Epiri_numini',\n",
       "  'numini_eorum',\n",
       "  'eorum_dicatissimus'],\n",
       " ['Imperatori_Caesari',\n",
       "  'Caesari_Marco',\n",
       "  'Marco_Annio',\n",
       "  'Annio_Floriano',\n",
       "  'Floriano_Pio',\n",
       "  'Pio_Felici',\n",
       "  'Felici_Augusto',\n",
       "  'Augusto_patri',\n",
       "  'patri_patriae',\n",
       "  'patriae_milia',\n",
       "  'milia_passuum',\n",
       "  'passuum_III',\n",
       "  'III_Imperatori',\n",
       "  'Imperatori_Caesari',\n",
       "  'Caesari_Marco',\n",
       "  'Marco_Aurelio',\n",
       "  'Aurelio_Probo',\n",
       "  'Probo_Pio',\n",
       "  'Pio_Felici',\n",
       "  'Felici_Augusto',\n",
       "  'Augusto_milia',\n",
       "  'milia_passuum',\n",
       "  'passuum_II'],\n",
       " ['Tiberius_Claudius',\n",
       "  'Claudius_Caesar',\n",
       "  'Caesar_Augustus',\n",
       "  'Augustus_Germanicus',\n",
       "  'Germanicus_pontifex',\n",
       "  'pontifex_maximus',\n",
       "  'maximus_tribunicia',\n",
       "  'tribunicia_potestate',\n",
       "  'potestate_VIIII',\n",
       "  'VIIII_imperator',\n",
       "  'imperator_XVI',\n",
       "  'XVI_pater',\n",
       "  'pater_patriae',\n",
       "  'patriae_dicit',\n",
       "  'dicit_cum',\n",
       "  'cum_et',\n",
       "  'et_colonias',\n",
       "  'colonias_et',\n",
       "  'et_municipia',\n",
       "  'municipia_non',\n",
       "  'non_solum',\n",
       "  'solum_Italiae',\n",
       "  'Italiae_verum',\n",
       "  'verum_etiam',\n",
       "  'etiam_provinciarum',\n",
       "  'provinciarum_item',\n",
       "  'item_civitatium',\n",
       "  'civitatium_cuius',\n",
       "  'cuius_que',\n",
       "  'que_provinciae',\n",
       "  'provinciae_lebare',\n",
       "  'lebare_oneribus',\n",
       "  'oneribus_vehiculorum',\n",
       "  'vehiculorum_praebendorum',\n",
       "  'praebendorum_saepe',\n",
       "  'saepe_temptavissem',\n",
       "  'temptavissem_et',\n",
       "  'et_cum',\n",
       "  'cum_satis',\n",
       "  'satis_multa',\n",
       "  'multa_remedia',\n",
       "  'remedia_invenisse',\n",
       "  'invenisse_mihi',\n",
       "  'mihi_viderer',\n",
       "  'viderer_potuit',\n",
       "  'potuit_tamen',\n",
       "  'tamen_nequitiae',\n",
       "  'nequitiae_hominum',\n",
       "  'hominum_C',\n",
       "  'C_RAS',\n",
       "  'RAS_RVM',\n",
       "  'RVM_aut',\n",
       "  'aut_falsa',\n",
       "  'falsa_nomina',\n",
       "  'nomina_ius',\n",
       "  'ius_dedit',\n",
       "  'dedit_turo',\n",
       "  'turo_ante',\n",
       "  'ante_diem'],\n",
       " ['Pro_salute',\n",
       "  'salute_Imperatorum',\n",
       "  'Imperatorum_Caesaris',\n",
       "  'Caesaris_Luci',\n",
       "  'Luci_Septimi',\n",
       "  'Septimi_Severi',\n",
       "  'Severi_et',\n",
       "  'et_Marci',\n",
       "  'Marci_Aureli',\n",
       "  'Aureli_Antonini',\n",
       "  'Antonini_Auggustorum',\n",
       "  'Auggustorum_et',\n",
       "  'et_Publi',\n",
       "  'Publi_Septimi',\n",
       "  'Septimi_Gaetae',\n",
       "  'Gaetae_Caesaris',\n",
       "  'Caesaris_Marcus',\n",
       "  'Marcus_Aurelius',\n",
       "  'Aurelius_Rufinus',\n",
       "  'Rufinus_evocatus',\n",
       "  'evocatus_Auggustorum',\n",
       "  'Auggustorum_nnostrorum',\n",
       "  'nnostrorum_Sancto',\n",
       "  'Sancto_Deo',\n",
       "  'Deo_Invicto',\n",
       "  'Invicto_speleum',\n",
       "  'speleum_constituit',\n",
       "  'constituit_cum',\n",
       "  'cum_militibus',\n",
       "  'militibus_praetorianis',\n",
       "  'praetorianis_Flavio',\n",
       "  'Flavio_Clarino',\n",
       "  'Clarino_Aelio',\n",
       "  'Aelio_Messio',\n",
       "  'Messio_Aurelio',\n",
       "  'Aurelio_Iuliano'],\n",
       " ['Octavius_Salutaris']]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDHg_bigrams_ = [get_bigrams_underscore(inscr_text) for inscr_text in inscr_texts]\n",
    "EDHg_bigrams_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fortissimo_et',\n",
       " 'et_piissimo',\n",
       " 'piissimo_Caesari',\n",
       " 'Caesari_domino',\n",
       " 'domino_nostro',\n",
       " 'nostro_Galerio',\n",
       " 'Galerio_Valerio',\n",
       " 'Valerio_Maximiano',\n",
       " 'Maximiano_Pio',\n",
       " 'Pio_Felici']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_list = [el for sublist in EDHg_bigrams_ for el in sublist]\n",
    "bigrams_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258720"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique bigrams do we have?\n",
    "len(list(set(bigrams_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dis_Manibus',\n",
       " 'vixit_annos',\n",
       " 'votum_solvit',\n",
       " 'solvit_libens',\n",
       " 'libens_merito',\n",
       " 'Iovi_Optimo',\n",
       " 'Optimo_Maximo',\n",
       " 'hic_situs',\n",
       " 'situs_est',\n",
       " 'tribunicia_potestate']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok, let's list only 1000 of the most common\n",
    "N = 100\n",
    "bigrams_N = nltk.FreqDist(bigrams_list).most_common(N)\n",
    "bigrams_N = [tup[0] for tup in bigrams_N]\n",
    "bigrams_N[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_bigrams_list = []\n",
    "status_list = []\n",
    "for el_status, el_bigrams in zip(EDHg[\"status_list\"].tolist(), EDHg_bigrams_):\n",
    "    try: el_status = eval(el_status)\n",
    "    except: pass\n",
    "    if isinstance(el_status, list):\n",
    "        new_el = el_status\n",
    "    elif isinstance(el, str):\n",
    "        new_el = [el]\n",
    "    else: \n",
    "        new_el = []\n",
    "    new_el = [el.replace(\" \", \"_\") for el in new_el]\n",
    "    status_list.append(new_el)\n",
    "    new_el = new_el + el_bigrams\n",
    "    new_el = \" \".join(new_el)\n",
    "    status_bigrams_list.append(new_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(status_list_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['viri',\n",
       " 'tria_nomina',\n",
       " 'tituli_sepulcrales',\n",
       " 'mulieres',\n",
       " 'tituli_sacri',\n",
       " 'milites',\n",
       " 'nomen_singulare',\n",
       " 'Augusti/Augustae',\n",
       " 'tituli_operum',\n",
       " 'tituli_fabricationis']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_list_flat = [el for sublist in status_list for el in sublist]\n",
    "status_N = [tup[0] for tup in nltk.FreqDist(status_list_flat).most_common(100)] ### we had 228 in total\n",
    "status_N[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(status_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = status_N + bigrams_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r\"\\w+\\/?|\\_\\w+\", vocabulary=vocab)\n",
    "X = vectorizer.fit_transform(status_bigrams_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49916, 137)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X, y):\n",
    "    \"\"\"\n",
    "    Create and train the Support Vector Machine.\n",
    "    \"\"\"\n",
    "    svm = SVC(C=1000000.0, gamma='auto', kernel='rbf')\n",
    "    svm.fit(X, y)\n",
    "    return svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm = train_svm(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svm.predict(X_test)\n",
    "print(svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socdiv_venv",
   "language": "python",
   "name": "socdiv_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
